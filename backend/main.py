from fastapi import FastAPI, HTTPException, Depends, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import asyncio
import json
import uuid
from datetime import datetime
import os
from openai import AsyncOpenAI
from contextlib import asynccontextmanager
from dotenv import load_dotenv
import PyPDF2
import docx
from PIL import Image
import pytesseract
import io
import tempfile

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()


# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = AsyncOpenAI(
    api_key=os.getenv("OPENAI_API_KEY", "your-openai-api-key-here")
)

# ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ ì„¤ì •
AVAILABLE_MODELS = {
    "gpt-4o": {
        "name": "GPT-4o",
        "description": "OpenAIì˜ ìµœì‹  ë©€í‹°ëª¨ë‹¬ ëª¨ë¸",
        "provider": "openai",
        "supports_web_search": True,
        "max_tokens": 4000,
        "temperature": 0.7
    },
    "gpt-4": {
        "name": "GPT-4",
        "description": "OpenAIì˜ ê°•ë ¥í•œ ì–¸ì–´ ëª¨ë¸",
        "provider": "openai", 
        "supports_web_search": True,
        "max_tokens": 4000,
        "temperature": 0.7
    },
    "gpt-3.5-turbo": {
        "name": "GPT-3.5 Turbo",
        "description": "ë¹ ë¥´ê³  íš¨ìœ¨ì ì¸ OpenAI ëª¨ë¸",
        "provider": "openai",
        "supports_web_search": False,
        "max_tokens": 2000,
        "temperature": 0.7
    }
}

# ë©”ëª¨ë¦¬ ì €ì¥ì†Œ (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš©)
sessions_db: Dict[str, Dict] = {}
messages_db: Dict[str, List[Dict]] = {}

# Pydantic ëª¨ë¸ë“¤
class ChatMessage(BaseModel):
    id: str
    content: str
    role: str  # 'user' or 'assistant'
    timestamp: datetime
    sessionId: str

class ChatRequest(BaseModel):
    content: str
    sessionId: str
    model: Optional[str] = "gpt-4o"  # ê¸°ë³¸ê°’ì€ gpt-4o
    webSearch: Optional[bool] = False  # ì›¹ ê²€ìƒ‰ ì—¬ë¶€

class ChatResponse(BaseModel):
    id: str
    content: str
    role: str
    timestamp: datetime
    sessionId: str

class ChatSession(BaseModel):
    id: str
    title: str
    createdAt: datetime
    updatedAt: datetime
    messageCount: int

class SessionCreateRequest(BaseModel):
    title: Optional[str] = None

class SessionUpdateRequest(BaseModel):
    title: str

class ChatSearch(BaseModel):
    query: Optional[str] = None
    page: int = 0
    size: int = 50
    sort: Optional[str] = None

class ChatSessionList(BaseModel):
    sessions: List[ChatSession]
    totalElements: int
    totalPages: int
    currentPage: int
    size: int

class ChatHistory(BaseModel):
    messages: List[ChatMessage]
    sessionId: str
    totalCount: int

class ChatStreamChunk(BaseModel):
    id: str
    content: str
    role: str
    timestamp: datetime
    sessionId: str
    isComplete: bool = False

# íŒŒì¼ ì²˜ë¦¬ í•¨ìˆ˜ë“¤
async def extract_text_from_pdf(file_content: bytes) -> str:
    """PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        pdf_file = io.BytesIO(file_content)
        pdf_reader = PyPDF2.PdfReader(pdf_file)
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text() + "\n"
        return text.strip()
    except Exception as e:
        return f"PDF ì½ê¸° ì˜¤ë¥˜: {str(e)}"

async def extract_text_from_docx(file_content: bytes) -> str:
    """DOCX íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        doc_file = io.BytesIO(file_content)
        doc = docx.Document(doc_file)
        text = ""
        for paragraph in doc.paragraphs:
            text += paragraph.text + "\n"
        return text.strip()
    except Exception as e:
        return f"DOCX ì½ê¸° ì˜¤ë¥˜: {str(e)}"

async def extract_text_from_image(file_content: bytes) -> str:
    """ì´ë¯¸ì§€ì—ì„œ OCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        image = Image.open(io.BytesIO(file_content))
        text = pytesseract.image_to_string(image, lang='kor+eng')
        return text.strip() if text.strip() else "ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    except Exception as e:
        return f"ì´ë¯¸ì§€ OCR ì˜¤ë¥˜: {str(e)}"

async def process_uploaded_file(file: UploadFile) -> str:
    """ì—…ë¡œë“œëœ íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        file_content = await file.read()
        file_type = file.content_type.lower()
        filename = file.filename.lower()
        
        if file_type == "application/pdf" or filename.endswith('.pdf'):
            return await extract_text_from_pdf(file_content)
        elif file_type in ["application/vnd.openxmlformats-officedocument.wordprocessingml.document"] or filename.endswith('.docx'):
            return await extract_text_from_docx(file_content)
        elif file_type.startswith('image/'):
            return await extract_text_from_image(file_content)
        elif file_type == "text/plain" or filename.endswith('.txt'):
            return file_content.decode('utf-8', errors='ignore')
        else:
            return f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_type}"
    except Exception as e:
        return f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}"

# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
def generate_id() -> str:
    return str(uuid.uuid4())

def create_session(title: str = None) -> ChatSession:
    session_id = generate_id()
    session = ChatSession(
        id=session_id,
        title=title or f"ìƒˆ ì±„íŒ… {len(sessions_db) + 1}",
        createdAt=datetime.now(),
        updatedAt=datetime.now(),
        messageCount=0
    )
    
    sessions_db[session_id] = session.dict()
    messages_db[session_id] = []
    return session

def get_session(session_id: str) -> ChatSession:
    if session_id not in sessions_db:
        raise HTTPException(status_code=404, detail="Session not found")
    return ChatSession(**sessions_db[session_id])

def update_session_message_count(session_id: str):
    if session_id in sessions_db:
        sessions_db[session_id]["messageCount"] = len(messages_db.get(session_id, []))
        sessions_db[session_id]["updatedAt"] = datetime.now()

# ì´ˆê¸° ë°ëª¨ ë°ì´í„° ìƒì„±
def initialize_demo_data():
    if not sessions_db:
        # ë°ëª¨ ì„¸ì…˜ 1
        demo_session_1 = create_session("ì˜ì—… ë°ì´í„° ë¶„ì„")
        messages_db[demo_session_1.id] = [
            {
                "id": generate_id(),
                "content": "ì´ë²ˆ ë¶„ê¸° ì˜ì—… ì„±ê³¼ëŠ” ì–´ë–¤ê°€ìš”?",
                "role": "user",
                "timestamp": datetime.now(),
                "sessionId": demo_session_1.id
            },
            {
                "id": generate_id(),
                "content": "ì´ë²ˆ ë¶„ê¸° ì˜ì—… ì„±ê³¼ë¥¼ ë¶„ì„í•´ë³´ê² ìŠµë‹ˆë‹¤. ì „ì²´ì ìœ¼ë¡œ ëª©í‘œ ëŒ€ë¹„ 115% ë‹¬ì„±í–ˆìœ¼ë©°, íŠ¹íˆ ìƒˆë¡œìš´ ê³ ê° í™•ë³´ ë¶€ë¶„ì—ì„œ ì¢‹ì€ ì„±ê³¼ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.",
                "role": "assistant",
                "timestamp": datetime.now(),
                "sessionId": demo_session_1.id
            }
        ]
        
        # ë°ëª¨ ì„¸ì…˜ 2
        demo_session_2 = create_session("í”„ë¡œì íŠ¸ í˜„í™© ì¡°íšŒ")
        messages_db[demo_session_2.id] = [
            {
                "id": generate_id(),
                "content": "ì§„í–‰ ì¤‘ì¸ í”„ë¡œì íŠ¸ ëª©ë¡ì„ ë³´ì—¬ì£¼ì„¸ìš”",
                "role": "user",
                "timestamp": datetime.now(),
                "sessionId": demo_session_2.id
            },
            {
                "id": generate_id(),
                "content": "í˜„ì¬ ì§„í–‰ ì¤‘ì¸ í”„ë¡œì íŠ¸ëŠ” ì´ 12ê°œì…ë‹ˆë‹¤. ê·¸ ì¤‘ 5ê°œëŠ” ê°œë°œ ë‹¨ê³„, 4ê°œëŠ” í…ŒìŠ¤íŠ¸ ë‹¨ê³„, 3ê°œëŠ” ë°°í¬ ì¤€ë¹„ ë‹¨ê³„ì— ìˆìŠµë‹ˆë‹¤.",
                "role": "assistant",
                "timestamp": datetime.now(),
                "sessionId": demo_session_2.id
            }
        ]
        
        # ë°ëª¨ ì„¸ì…˜ 3
        demo_session_3 = create_session("ê³ ê°ì‚¬ ì •ë³´ ë¬¸ì˜")
        messages_db[demo_session_3.id] = []
        
        # ë©”ì‹œì§€ ì¹´ìš´íŠ¸ ì—…ë°ì´íŠ¸
        for session_id in sessions_db.keys():
            update_session_message_count(session_id)

# ì•± ì‹œì‘ ì‹œ ë°ëª¨ ë°ì´í„° ì´ˆê¸°í™” (ë¹„í™œì„±í™”)
@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    # initialize_demo_data()  # ë°ëª¨ ë°ì´í„° ìƒì„± ë¹„í™œì„±í™”
    yield
    # Shutdown
    pass

app = FastAPI(
    title="NSales Pro Chat API",
    description="AI ì±„íŒ… ì„œë¹„ìŠ¤ API",
    version="1.0.0",
    lifespan=lifespan
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173", "http://localhost:5174", "http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# API ì—”ë“œí¬ì¸íŠ¸ë“¤

@app.get("/")
async def root():
    return {"message": "NSales Pro Chat API", "version": "1.0.0"}

@app.get("/api/v1/health")
async def health_check():
    return {"status": "healthy", "timestamp": datetime.now()}

@app.get("/api/v1/models")
async def get_available_models():
    """ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ ëª©ë¡ ë°˜í™˜"""
    return {"models": AVAILABLE_MODELS}

# ì±„íŒ… ì„¸ì…˜ ê´€ë¦¬
@app.post("/api/v1/chat/sessions", response_model=ChatSession)
async def create_chat_session(request: SessionCreateRequest):
    session = create_session(request.title)
    return session

@app.get("/api/v1/chat/sessions", response_model=ChatSessionList)
async def get_chat_sessions(search: ChatSearch = Depends()):
    sessions = list(sessions_db.values())
    
    # ê²€ìƒ‰ í•„í„° ì ìš©
    if search.query:
        sessions = [
            s for s in sessions 
            if search.query.lower() in s["title"].lower()
        ]
    
    # ì •ë ¬ (ìµœì‹ ìˆœ)
    sessions.sort(key=lambda x: x["updatedAt"], reverse=True)
    
    # í˜ì´ì§•
    total = len(sessions)
    start = search.page * search.size
    end = start + search.size
    paged_sessions = sessions[start:end]
    
    return ChatSessionList(
        sessions=[ChatSession(**s) for s in paged_sessions],
        totalElements=total,
        totalPages=(total + search.size - 1) // search.size,
        currentPage=search.page,
        size=search.size
    )

@app.get("/api/v1/chat/sessions/{session_id}", response_model=ChatSession)
async def get_chat_session(session_id: str):
    return get_session(session_id)

@app.patch("/api/v1/chat/sessions/{session_id}")
async def update_chat_session(session_id: str, request: SessionUpdateRequest):
    if session_id not in sessions_db:
        raise HTTPException(status_code=404, detail="Session not found")
    
    sessions_db[session_id]["title"] = request.title
    sessions_db[session_id]["updatedAt"] = datetime.now()
    return {"message": "Session updated successfully"}

@app.delete("/api/v1/chat/sessions/{session_id}")
async def delete_chat_session(session_id: str):
    if session_id not in sessions_db:
        raise HTTPException(status_code=404, detail="Session not found")
    
    del sessions_db[session_id]
    if session_id in messages_db:
        del messages_db[session_id]
    
    return {"message": "Session deleted successfully"}

# ë©”ì‹œì§€ ê´€ë¦¬
@app.get("/api/v1/chat/sessions/{session_id}/messages", response_model=ChatHistory)
async def get_message_history(session_id: str):
    if session_id not in sessions_db:
        raise HTTPException(status_code=404, detail="Session not found")
    
    messages = messages_db.get(session_id, [])
    return ChatHistory(
        messages=[ChatMessage(**msg) for msg in messages],
        sessionId=session_id,
        totalCount=len(messages)
    )

@app.post("/api/v1/chat/messages/with-files")
async def send_message_with_files(
    content: str = Form(...),
    sessionId: str = Form(...),
    files: List[UploadFile] = File(default=[]),
    model: str = Form(default="gpt-4o")
):
    """íŒŒì¼ ì²¨ë¶€ë¥¼ ì§€ì›í•˜ëŠ” ì±„íŒ… ë©”ì‹œì§€ ì „ì†¡"""
    try:
        # ì„¸ì…˜ ì¡´ì¬ í™•ì¸
        if sessionId not in sessions_db:
            raise HTTPException(status_code=404, detail="Session not found")
        
        session_messages = messages_db.get(sessionId, [])
        
        # íŒŒì¼ ì²˜ë¦¬
        file_contents = []
        if files:
            for file in files:
                if file.filename:  # íŒŒì¼ì´ ì‹¤ì œë¡œ ì—…ë¡œë“œëœ ê²½ìš°
                    print(f"Processing file: {file.filename}, type: {file.content_type}")
                    file_text = await process_uploaded_file(file)
                    file_contents.append(f"[íŒŒì¼: {file.filename}]\n{file_text}")
        
        # ë©”ì‹œì§€ ë‚´ìš© êµ¬ì„± (í…ìŠ¤íŠ¸ + íŒŒì¼ ë‚´ìš©)
        message_content = content
        if file_contents:
            message_content += "\n\n" + "\n\n".join(file_contents)
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
        user_message = ChatMessage(
            id=generate_id(),
            content=message_content,
            role="user",
            timestamp=datetime.now(),
            sessionId=sessionId
        )
        session_messages.append(user_message.model_dump())
        
        # OpenAI APIì— ì „ë‹¬í•  ë©”ì‹œì§€ êµ¬ì„±
        conversation_messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ NSales Proì˜ ì˜ì—… AI ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì˜ì—… ë°ì´í„° ë¶„ì„, í”„ë¡œì íŠ¸ ì •ë³´ ì¡°íšŒ, ì—…ë¬´ ê´€ë ¨ ì§ˆë¬¸ì— ë„ì›€ì„ ì£¼ì„¸ìš”. í•œêµ­ì–´ë¡œ ì¹œê·¼í•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”. ì²¨ë¶€ëœ íŒŒì¼ì˜ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ê´€ë ¨ëœ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”. ìµœì‹  ì •ë³´ê°€ í•„ìš”í•˜ê±°ë‚˜ ì‹¤ì‹œê°„ ë°ì´í„°, ë‰´ìŠ¤, ì‹œì¥ ë™í–¥ ë“±ì„ ì§ˆë¬¸ë°›ìœ¼ë©´ ì›¹ ê²€ìƒ‰ì„ ì ê·¹ í™œìš©í•˜ì—¬ ì •í™•í•˜ê³  ìµœì‹ ì˜ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”."}
        ]
        
        # ê¸°ì¡´ ëŒ€í™” ë‚´ìš© ì¶”ê°€ (ìµœê·¼ 20ê°œ ë©”ì‹œì§€ë§Œ ìœ ì§€)
        recent_messages = session_messages[-21:] if len(session_messages) > 21 else session_messages[:-1]  # í˜„ì¬ ë©”ì‹œì§€ ì œì™¸
        for msg in recent_messages:
            conversation_messages.append({
                "role": msg["role"],
                "content": msg["content"]
            })
        
        # í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        conversation_messages.append({"role": "user", "content": message_content})
        
        # ì„ íƒëœ ëª¨ë¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        selected_model = model if model in AVAILABLE_MODELS else "gpt-4o"
        model_config = AVAILABLE_MODELS[selected_model]

        # OpenAI API í˜¸ì¶œ
        try:
            print(f"Using model: {selected_model} ({model_config['name']})")
            print(f"Conversation length: {len(conversation_messages)} messages")
            print(f"Files processed: {len(file_contents)}")
            
            # ì›¹ ê²€ìƒ‰ ì—¬ë¶€ëŠ” form ë°ì´í„°ì—ì„œ í™•ì¸
            web_search = form.get('webSearch', 'false').lower() == 'true'
            needs_web_search = web_search
            
            if needs_web_search and model_config["supports_web_search"]:
                print("ğŸ” Web search detected - using Responses API with web search")
                try:
                    # OpenAI Responses APIë¥¼ ì‚¬ìš©í•œ ì›¹ ê²€ìƒ‰
                    response = await client.responses.create(
                        model=selected_model,
                        input=content,
                        tools=[
                            {
                                "type": "web_search"
                            }
                        ]
                    )
                    
                    # Extract message content from output
                    ai_content = ""
                    sources = []
                    
                    for output_item in response.output:
                        if output_item.type == 'message' and hasattr(output_item, 'content'):
                            for content_item in output_item.content:
                                if content_item.type == 'output_text':
                                    ai_content += content_item.text
                                    
                                    # Extract URL citations from annotations
                                    if hasattr(content_item, 'annotations'):
                                        for annotation in content_item.annotations:
                                            if annotation.type == 'url_citation':
                                                sources.append({
                                                    'title': getattr(annotation, 'title', ''),
                                                    'url': getattr(annotation, 'url', ''),
                                                    'snippet': ''
                                                })
                    
                    # Add sources to the content if found
                    if sources:
                        sources_text = "\n\n**ì°¸ê³  ì¶œì²˜:**\n"
                        for i, source in enumerate(sources, 1):
                            sources_text += f"{i}. [{source['title']}]({source['url']})\n"
                        ai_content += sources_text
                        print(f"ğŸ“š Found {len(sources)} web search sources")
                except Exception as e:
                    print(f"Responses API error, falling back to chat completions: {e}")
                    # Responses APIê°€ ì‘ë™í•˜ì§€ ì•Šìœ¼ë©´ ì¼ë°˜ ì±„íŒ…ìœ¼ë¡œ í´ë°±
                    response = await client.chat.completions.create(
                        model="gpt-4o",
                        messages=conversation_messages,
                        max_tokens=1500,
                        temperature=0.7
                    )
                    ai_content = response.choices[0].message.content
            else:
                response = await client.chat.completions.create(
                    model=selected_model,
                    messages=conversation_messages,
                    max_tokens=model_config["max_tokens"],
                    temperature=model_config["temperature"]
                )
                ai_content = response.choices[0].message.content
            
            print(f"OpenAI Response: {ai_content}")
            
        except Exception as e:
            print(f"OpenAI API Error: {e}")
            ai_content = f"ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ AI ì„œë¹„ìŠ¤ì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì²¨ë¶€í•˜ì‹  íŒŒì¼ì„ í¬í•¨í•œ '{content}'ì— ëŒ€í•œ ë‹µë³€ì„ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        
        # AI ì‘ë‹µ ì €ì¥
        ai_message = ChatMessage(
            id=generate_id(),
            content=ai_content,
            role="assistant",
            timestamp=datetime.now(),
            sessionId=sessionId
        )
        session_messages.append(ai_message.model_dump())
        
        # ë©”ì‹œì§€ ì €ì¥
        messages_db[sessionId] = session_messages
        
        # ì„¸ì…˜ ì—…ë°ì´íŠ¸
        sessions_db[sessionId]["messageCount"] = len(session_messages)
        sessions_db[sessionId]["updatedAt"] = datetime.now()
        
        return {
            "userMessage": user_message,
            "aiMessage": ai_message,
            "success": True
        }
        
    except Exception as e:
        print(f"Error in send_message_with_files: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/v1/chat/messages", response_model=ChatResponse)
async def send_message(request: ChatRequest):
    if request.sessionId not in sessions_db:
        raise HTTPException(status_code=404, detail="Session not found")
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
    user_message = ChatMessage(
        id=generate_id(),
        content=request.content,
        role="user",
        timestamp=datetime.now(),
        sessionId=request.sessionId
    )
    
    if request.sessionId not in messages_db:
        messages_db[request.sessionId] = []
    
    messages_db[request.sessionId].append(user_message.dict())
    
    # ì„¸ì…˜ì˜ ê¸°ì¡´ ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸°
    session_messages = messages_db.get(request.sessionId, [])
    
    # OpenAI APIì— ì „ë‹¬í•  ë©”ì‹œì§€ êµ¬ì„±
    conversation_messages = [
        {"role": "system", "content": "ë‹¹ì‹ ì€ NSales Proì˜ ì˜ì—… AI ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì˜ì—… ë°ì´í„° ë¶„ì„, í”„ë¡œì íŠ¸ ì •ë³´ ì¡°íšŒ, ì—…ë¬´ ê´€ë ¨ ì§ˆë¬¸ì— ë„ì›€ì„ ì£¼ì„¸ìš”. í•œêµ­ì–´ë¡œ ì¹œê·¼í•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”. ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ê¸°ì–µí•˜ê³  ë¬¸ë§¥ì„ ìœ ì§€í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”. ìµœì‹  ì •ë³´ê°€ í•„ìš”í•˜ê±°ë‚˜ ì‹¤ì‹œê°„ ë°ì´í„°, ë‰´ìŠ¤, ì‹œì¥ ë™í–¥ ë“±ì„ ì§ˆë¬¸ë°›ìœ¼ë©´ ì›¹ ê²€ìƒ‰ì„ ì ê·¹ í™œìš©í•˜ì—¬ ì •í™•í•˜ê³  ìµœì‹ ì˜ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”."}
    ]
    
    # ê¸°ì¡´ ëŒ€í™” ë‚´ìš© ì¶”ê°€ (ìµœê·¼ 10ê°œ ë©”ì‹œì§€ë§Œ ìœ ì§€í•˜ì—¬ í† í° ì ˆì•½)
    recent_messages = session_messages[-20:] if len(session_messages) > 20 else session_messages
    for msg in recent_messages:
        conversation_messages.append({
            "role": msg["role"],
            "content": msg["content"]
        })
    
    # í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    conversation_messages.append({"role": "user", "content": request.content})
    
    # ì„ íƒëœ ëª¨ë¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    selected_model = request.model if request.model in AVAILABLE_MODELS else "gpt-4o"
    model_config = AVAILABLE_MODELS[selected_model]
    
    # OpenAI API í˜¸ì¶œ
    try:
        print(f"Using model: {selected_model} ({model_config['name']})")
        print(f"OpenAI API Key: {os.getenv('OPENAI_API_KEY')[:20]}...")  # ë””ë²„ê¹…ìš©
        print(f"Conversation length: {len(conversation_messages)} messages")  # ë””ë²„ê¹…ìš©
        
        # ì›¹ ê²€ìƒ‰ ì—¬ë¶€ëŠ” ìš”ì²­ì—ì„œ í™•ì¸
        needs_web_search = getattr(request, 'webSearch', False)
        search_content = request.content
        
        # ì›¹ ê²€ìƒ‰ì€ ì§€ì›í•˜ëŠ” ëª¨ë¸ì—ì„œë§Œ ê°€ëŠ¥
        if needs_web_search and model_config["supports_web_search"]:
            print("ğŸ” Web search detected - using Responses API with web search")
            try:
                # OpenAI Responses APIë¥¼ ì‚¬ìš©í•œ ì›¹ ê²€ìƒ‰
                response = await client.responses.create(
                    model=selected_model,
                    input=search_content,
                    tools=[
                        {
                            "type": "web_search"
                        }
                    ]
                )
                
                # Extract message content from output
                ai_content = ""
                sources = []
                
                for output_item in response.output:
                    if output_item.type == 'message' and hasattr(output_item, 'content'):
                        for content_item in output_item.content:
                            if content_item.type == 'output_text':
                                ai_content += content_item.text
                                
                                # Extract URL citations from annotations
                                if hasattr(content_item, 'annotations'):
                                    for annotation in content_item.annotations:
                                        if annotation.type == 'url_citation':
                                            sources.append({
                                                'title': getattr(annotation, 'title', ''),
                                                'url': getattr(annotation, 'url', ''),
                                                'snippet': ''
                                            })
                
                # Add sources to the content if found
                if sources:
                    sources_text = "\n\n**ì°¸ê³  ì¶œì²˜:**\n"
                    for i, source in enumerate(sources, 1):
                        sources_text += f"{i}. [{source['title']}]({source['url']})\n"
                    ai_content += sources_text
                    print(f"ğŸ“š Found {len(sources)} web search sources")
            except Exception as e:
                print(f"Responses API error, falling back to chat completions: {e}")
                # Responses APIê°€ ì‘ë™í•˜ì§€ ì•Šìœ¼ë©´ ì¼ë°˜ ì±„íŒ…ìœ¼ë¡œ í´ë°±
                response = await client.chat.completions.create(
                    model=selected_model,
                    messages=conversation_messages,
                    max_tokens=model_config["max_tokens"],
                    temperature=model_config["temperature"]
                )
                ai_content = response.choices[0].message.content
        else:
            response = await client.chat.completions.create(
                model=selected_model,
                messages=conversation_messages,
                max_tokens=model_config["max_tokens"],
                temperature=model_config["temperature"]
            )
            ai_content = response.choices[0].message.content
        
        print(f"OpenAI Response: {ai_content}")  # ë””ë²„ê¹…ìš©
        
    except Exception as e:
        # OpenAI API ì˜¤ë¥˜ ì‹œ í´ë°± ì‘ë‹µ
        print(f"OpenAI API Error: {e}")  # ë””ë²„ê¹…ìš©
        ai_content = f"ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ AI ì„œë¹„ìŠ¤ì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. '{request.content}'ì— ëŒ€í•œ ë‹µë³€ì„ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    
    # AI ì‘ë‹µ ì €ì¥
    ai_message = ChatMessage(
        id=generate_id(),
        content=ai_content,
        role="assistant",
        timestamp=datetime.now(),
        sessionId=request.sessionId
    )
    
    messages_db[request.sessionId].append(ai_message.dict())
    update_session_message_count(request.sessionId)
    
    return ChatResponse(**ai_message.dict())

# ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ…
@app.post("/api/v1/chat/stream")
async def stream_chat(request: ChatRequest):
    if request.sessionId not in sessions_db:
        raise HTTPException(status_code=404, detail="Session not found")
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
    user_message = ChatMessage(
        id=generate_id(),
        content=request.content,
        role="user",
        timestamp=datetime.now(),
        sessionId=request.sessionId
    )
    
    if request.sessionId not in messages_db:
        messages_db[request.sessionId] = []
    
    messages_db[request.sessionId].append(user_message.dict())
    
    async def generate_stream():
        ai_message_id = generate_id()
        full_content = ""
        
        # ì„¸ì…˜ì˜ ê¸°ì¡´ ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸°
        session_messages = messages_db.get(request.sessionId, [])
        
        # OpenAI APIì— ì „ë‹¬í•  ë©”ì‹œì§€ êµ¬ì„±
        conversation_messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ NSales Proì˜ ì˜ì—… AI ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì˜ì—… ë°ì´í„° ë¶„ì„, í”„ë¡œì íŠ¸ ì •ë³´ ì¡°íšŒ, ì—…ë¬´ ê´€ë ¨ ì§ˆë¬¸ì— ë„ì›€ì„ ì£¼ì„¸ìš”. í•œêµ­ì–´ë¡œ ì¹œê·¼í•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”. ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ê¸°ì–µí•˜ê³  ë¬¸ë§¥ì„ ìœ ì§€í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”. ìµœì‹  ì •ë³´ê°€ í•„ìš”í•˜ê±°ë‚˜ ì‹¤ì‹œê°„ ë°ì´í„°, ë‰´ìŠ¤, ì‹œì¥ ë™í–¥ ë“±ì„ ì§ˆë¬¸ë°›ìœ¼ë©´ ì›¹ ê²€ìƒ‰ì„ ì ê·¹ í™œìš©í•˜ì—¬ ì •í™•í•˜ê³  ìµœì‹ ì˜ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”."}
        ]
        
        # ê¸°ì¡´ ëŒ€í™” ë‚´ìš© ì¶”ê°€ (ìµœê·¼ 20ê°œ ë©”ì‹œì§€ë§Œ ìœ ì§€í•˜ì—¬ í† í° ì ˆì•½)
        recent_messages = session_messages[-20:] if len(session_messages) > 20 else session_messages
        for msg in recent_messages:
            conversation_messages.append({
                "role": msg["role"],
                "content": msg["content"]
            })
        
        # í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        conversation_messages.append({"role": "user", "content": request.content})
        
        try:
            # ì„ íƒëœ ëª¨ë¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            selected_model = request.model if request.model in AVAILABLE_MODELS else "gpt-4o"
            model_config = AVAILABLE_MODELS[selected_model]
            
            print(f"Stream using model: {selected_model} ({model_config['name']})")
            print(f"Stream conversation length: {len(conversation_messages)} messages")  # ë””ë²„ê¹…ìš©
            
            # ì›¹ ê²€ìƒ‰ ì—¬ë¶€ëŠ” í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ê²°ì • (webSearch íŒŒë¼ë¯¸í„°ë¡œ ì „ë‹¬)
            needs_web_search = getattr(request, 'webSearch', False)
            search_content = request.content
            
            if needs_web_search and model_config["supports_web_search"]:
                print("ğŸ” Web search detected in stream - using Responses API")
                try:
                    # ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•œ ê²½ìš° ìŠ¤íŠ¸ë¦¬ë° ëŒ€ì‹  ì¼ë°˜ ì‘ë‹µ ì‚¬ìš©
                    response = await client.responses.create(
                        model=selected_model,
                        input=search_content,
                        tools=[
                            {
                                "type": "web_search"
                            }
                        ]
                    )
                    
                    # Extract message content from output
                    ai_content = ""
                    sources = []
                    
                    for output_item in response.output:
                        if output_item.type == 'message' and hasattr(output_item, 'content'):
                            for content_item in output_item.content:
                                if content_item.type == 'output_text':
                                    ai_content += content_item.text
                                    
                                    # Extract URL citations from annotations
                                    if hasattr(content_item, 'annotations'):
                                        for annotation in content_item.annotations:
                                            if annotation.type == 'url_citation':
                                                sources.append({
                                                    'title': getattr(annotation, 'title', ''),
                                                    'url': getattr(annotation, 'url', ''),
                                                    'snippet': ''
                                                })
                    
                    # Add sources to the content if found
                    if sources:
                        sources_text = "\n\n**ì°¸ê³  ì¶œì²˜:**\n"
                        for i, source in enumerate(sources, 1):
                            sources_text += f"{i}. [{source['title']}]({source['url']})\n"
                        ai_content += sources_text
                        print(f"ğŸ“š Found {len(sources)} web search sources in stream")
                    
                    full_content = ai_content
                    
                    # ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ìŠ¤íŠ¸ë¦¬ë°
                    import re
                    
                    # ë¬¸ìë³„ë¡œ ìŠ¤íŠ¸ë¦¬ë° (ë” ìì—°ìŠ¤ëŸ½ê²Œ)
                    for i, char in enumerate(ai_content):
                        stream_chunk = ChatStreamChunk(
                            id=ai_message_id,
                            content=char,
                            role="assistant",
                            timestamp=datetime.now(),
                            sessionId=request.sessionId,
                            isComplete=False
                        )
                        yield f"data: {stream_chunk.json()}\n\n"
                        
                        # ë¬¸ì ìœ í˜•ì— ë”°ë¥¸ ì ì‘ì  ì§€ì—°
                        if char in ".!?":
                            await asyncio.sleep(0.15)  # ë¬¸ì¥ ë
                        elif char in ",;:":
                            await asyncio.sleep(0.08)  # ë¬¸ì¥ ì¤‘ê°„
                        elif char == '\n':
                            await asyncio.sleep(0.12)  # ì¤„ë°”ê¿ˆ
                        elif char == ' ':
                            await asyncio.sleep(0.03)  # ê³µë°±
                        elif char in "()[]{}":
                            await asyncio.sleep(0.05)  # ê´„í˜¸
                        else:
                            await asyncio.sleep(0.02)  # ì¼ë°˜ ë¬¸ì
                    
                    # ì›¹ ê²€ìƒ‰ ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ ì‹ í˜¸
                    final_chunk = ChatStreamChunk(
                        id=ai_message_id,
                        content="",
                        role="assistant",
                        timestamp=datetime.now(),
                        sessionId=request.sessionId,
                        isComplete=True
                    )
                    yield f"data: {final_chunk.json()}\\n\\n"
                    
                    # ì›¹ ê²€ìƒ‰ ì„±ê³µ ì‹œ ì—¬ê¸°ì„œ return
                    # AI ì‘ë‹µ ì €ì¥
                    ai_message = ChatMessage(
                        id=ai_message_id,
                        content=full_content,
                        role="assistant",
                        timestamp=datetime.now(),
                        sessionId=request.sessionId
                    )
                    
                    messages_db[request.sessionId].append(ai_message.dict())
                    update_session_message_count(request.sessionId)
                    return
                        
                except Exception as web_error:
                    print(f"Responses API error in stream, falling back to chat completions: {web_error}")
                    # ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ì¼ë°˜ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ í´ë°±
                    stream = await client.chat.completions.create(
                        model=selected_model,
                        messages=conversation_messages,
                        max_tokens=model_config["max_tokens"],
                        temperature=model_config["temperature"],
                        stream=True
                    )
            else:
                # ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•˜ì§€ ì•Šì€ ê²½ìš° ì¼ë°˜ ìŠ¤íŠ¸ë¦¬ë° ì‚¬ìš©
                stream = await client.chat.completions.create(
                    model=selected_model,
                    messages=conversation_messages,
                    max_tokens=model_config["max_tokens"],
                    temperature=model_config["temperature"],
                    stream=True
                )
            
            # ì¼ë°˜ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ (ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨í•˜ê±°ë‚˜ ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•˜ì§€ ì•Šì€ ê²½ìš°)
            async for chunk in stream:
                if chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    full_content += content
                
                    stream_chunk = ChatStreamChunk(
                        id=ai_message_id,
                        content=content,
                        role="assistant",
                        timestamp=datetime.now(),
                        sessionId=request.sessionId,
                        isComplete=False
                    )
                    
                    yield f"data: {stream_chunk.json()}\n\n"
                    await asyncio.sleep(0.01)  # ì•½ê°„ì˜ ì§€ì—°ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ìŠ¤íŠ¸ë¦¬ë° íš¨ê³¼
            
            # ì™„ë£Œ ì‹ í˜¸
            final_chunk = ChatStreamChunk(
                id=ai_message_id,
                content="",
                role="assistant",
                timestamp=datetime.now(),
                sessionId=request.sessionId,
                isComplete=True
            )
            yield f"data: {final_chunk.json()}\n\n"
            
        except Exception as e:
            # OpenAI API ì˜¤ë¥˜ ì‹œ í´ë°± ì‘ë‹µ
            fallback_content = f"ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ AI ì„œë¹„ìŠ¤ì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. '{request.content}'ì— ëŒ€í•œ ë‹µë³€ì„ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            full_content = fallback_content
            
            # í´ë°± ì‘ë‹µì„ ë‹¨ì–´ ë‹¨ìœ„ë¡œ ìŠ¤íŠ¸ë¦¬ë°
            words = fallback_content.split()
            for i, word in enumerate(words):
                stream_chunk = ChatStreamChunk(
                    id=ai_message_id,
                    content=word + " ",
                    role="assistant",
                    timestamp=datetime.now(),
                    sessionId=request.sessionId,
                    isComplete=i == len(words) - 1
                )
                yield f"data: {stream_chunk.json()}\n\n"
                await asyncio.sleep(0.1)
        
        # AI ì‘ë‹µ ì €ì¥
        ai_message = ChatMessage(
            id=ai_message_id,
            content=full_content,
            role="assistant",
            timestamp=datetime.now(),
            sessionId=request.sessionId
        )
        
        messages_db[request.sessionId].append(ai_message.dict())
        update_session_message_count(request.sessionId)
    
    return StreamingResponse(
        generate_stream(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"  # Nginx ë²„í¼ë§ ë¹„í™œì„±í™”
        }
    )

@app.delete("/api/v1/chat/messages/{message_id}")
async def delete_message(message_id: str):
    for session_id, messages in messages_db.items():
        for i, msg in enumerate(messages):
            if msg["id"] == message_id:
                del messages[i]
                update_session_message_count(session_id)
                return {"message": "Message deleted successfully"}
    
    raise HTTPException(status_code=404, detail="Message not found")

@app.post("/api/v1/chat/messages/{message_id}/regenerate", response_model=ChatResponse)
async def regenerate_message(message_id: str):
    for session_id, messages in messages_db.items():
        for i, msg in enumerate(messages):
            if msg["id"] == message_id and msg["role"] == "assistant":
                # ì´ì „ ì‚¬ìš©ì ë©”ì‹œì§€ ì°¾ê¸°
                user_message = None
                if i > 0:
                    user_message = messages[i-1]
                
                if not user_message:
                    raise HTTPException(status_code=400, detail="Cannot regenerate: no previous user message found")
                
                try:
                    # ì„¸ì…˜ì˜ ê¸°ì¡´ ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸° (ì¬ìƒì„±í•  ë©”ì‹œì§€ ì œì™¸)
                    session_messages = messages_db.get(session_id, [])
                    
                    # OpenAI APIì— ì „ë‹¬í•  ë©”ì‹œì§€ êµ¬ì„±
                    conversation_messages = [
                        {"role": "system", "content": "ë‹¹ì‹ ì€ NSales Proì˜ ì˜ì—… AI ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì˜ì—… ë°ì´í„° ë¶„ì„, í”„ë¡œì íŠ¸ ì •ë³´ ì¡°íšŒ, ì—…ë¬´ ê´€ë ¨ ì§ˆë¬¸ì— ë„ì›€ì„ ì£¼ì„¸ìš”. í•œêµ­ì–´ë¡œ ì¹œê·¼í•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”. ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ê¸°ì–µí•˜ê³  ë¬¸ë§¥ì„ ìœ ì§€í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”."}
                    ]
                    
                    # ì¬ìƒì„±í•  ë©”ì‹œì§€ ì´ì „ê¹Œì§€ì˜ ëŒ€í™” ë‚´ìš© ì¶”ê°€
                    for j, msg in enumerate(session_messages):
                        if j >= i:  # ì¬ìƒì„±í•  ë©”ì‹œì§€ë¶€í„°ëŠ” ì œì™¸
                            break
                        conversation_messages.append({
                            "role": msg["role"],
                            "content": msg["content"]
                        })
                    
                    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
                    conversation_messages.append({"role": "user", "content": user_message["content"]})
                    
                    # OpenAI API í˜¸ì¶œ
                    response = await client.chat.completions.create(
                        model="gpt-4o",
                        messages=conversation_messages,
                        max_tokens=1000,
                        temperature=0.8  # ë” ë‹¤ì–‘í•œ ì‘ë‹µì„ ìœ„í•´ temperature ì¦ê°€
                    )
                    
                    new_content = response.choices[0].message.content
                    
                except Exception as e:
                    # OpenAI API ì˜¤ë¥˜ ì‹œ í´ë°± ì‘ë‹µ
                    new_content = f"ì£„ì†¡í•©ë‹ˆë‹¤. ë‹¤ì‹œ ìƒì„±í•˜ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. '{user_message['content']}'ì— ëŒ€í•œ ìƒˆë¡œìš´ ë‹µë³€ì„ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤."
                
                # ìƒˆë¡œìš´ ì‘ë‹µìœ¼ë¡œ êµì²´
                new_message = ChatMessage(
                    id=generate_id(),
                    content=new_content,
                    role="assistant",
                    timestamp=datetime.now(),
                    sessionId=session_id
                )
                
                messages[i] = new_message.dict()
                update_session_message_count(session_id)
                
                return ChatResponse(**new_message.dict())
    
    raise HTTPException(status_code=404, detail="Message not found")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)