from fastapi import FastAPI, HTTPException, Depends, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, RedirectResponse
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import asyncio
import json
import uuid
from datetime import datetime
import os
from openai import AsyncOpenAI
from contextlib import asynccontextmanager
from dotenv import load_dotenv
import PyPDF2
import docx
from PIL import Image
import pytesseract
import io
import tempfile

# Google ì„œë¹„ìŠ¤ import
try:
    from google_services import auth_service, calendar_service, gmail_service
    from google_functions import GOOGLE_TOOLS, FUNCTION_MAP
    GOOGLE_SERVICES_AVAILABLE = True
    print("âœ… Google ì„œë¹„ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
except ImportError as e:
    print(f"âš ï¸ Google ì„œë¹„ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
    GOOGLE_SERVICES_AVAILABLE = False
    GOOGLE_TOOLS = []
    FUNCTION_MAP = {}

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()


# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = AsyncOpenAI(
    api_key=os.getenv("OPENAI_API_KEY", "your-openai-api-key-here")
)

# ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ ì„¤ì •
AVAILABLE_MODELS = {
    "gpt-4o": {
        "name": "GPT-4o",
        "description": "OpenAIì˜ ìµœì‹  ë©€í‹°ëª¨ë‹¬ ëª¨ë¸",
        "provider": "openai",
        "supports_web_search": True,
        "max_tokens": 4000,
        "temperature": 0.7
    },
    "gpt-4": {
        "name": "GPT-4",
        "description": "OpenAIì˜ ê°•ë ¥í•œ ì–¸ì–´ ëª¨ë¸",
        "provider": "openai", 
        "supports_web_search": True,
        "max_tokens": 4000,
        "temperature": 0.7
    },
    "gpt-3.5-turbo": {
        "name": "GPT-3.5 Turbo",
        "description": "ë¹ ë¥´ê³  íš¨ìœ¨ì ì¸ OpenAI ëª¨ë¸",
        "provider": "openai",
        "supports_web_search": False,
        "max_tokens": 2000,
        "temperature": 0.7
    }
}

# ë©”ëª¨ë¦¬ ì €ì¥ì†Œ (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš©)
sessions_db: Dict[str, Dict] = {}
messages_db: Dict[str, List[Dict]] = {}

# Google ì„œë¹„ìŠ¤ ë„êµ¬ ì •ì˜
def get_google_tools():
    """Google ì„œë¹„ìŠ¤ í•¨ìˆ˜ë“¤ì„ OpenAI ë„êµ¬ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜"""
    return [
        {
            "type": "function",
            "function": {
                "name": "get_calendar_events",
                "description": "Google Calendarì—ì„œ ì¼ì •ì„ ì¡°íšŒí•©ë‹ˆë‹¤. ì˜¤ëŠ˜, ì´ë²ˆì£¼, ì´ë²ˆë‹¬ ë“±ì˜ ì¼ì •ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "time_period": {
                            "type": "string",
                            "enum": ["today", "tomorrow", "this_week", "next_week", "this_month", "next_month"],
                            "description": "ì¡°íšŒí•  ì‹œê°„ ë²”ìœ„"
                        },
                        "max_results": {
                            "type": "integer",
                            "default": 10,
                            "description": "ìµœëŒ€ ì¡°íšŒí•  ì¼ì • ìˆ˜"
                        }
                    },
                    "required": ["time_period"]
                }
            }
        },
        {
            "type": "function",
            "function": {
                "name": "create_calendar_event",
                "description": "Google Calendarì— ìƒˆë¡œìš´ ì¼ì •ì„ ìƒì„±í•©ë‹ˆë‹¤.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "summary": {
                            "type": "string",
                            "description": "ì¼ì • ì œëª©"
                        },
                        "description": {
                            "type": "string",
                            "description": "ì¼ì • ì„¤ëª…"
                        },
                        "start_datetime": {
                            "type": "string",
                            "description": "ì‹œì‘ ì¼ì‹œ (ISO 8601 í˜•ì‹: 2023-12-25T10:00:00)"
                        },
                        "end_datetime": {
                            "type": "string",
                            "description": "ì¢…ë£Œ ì¼ì‹œ (ISO 8601 í˜•ì‹: 2023-12-25T11:00:00)"
                        },
                        "attendees": {
                            "type": "array",
                            "items": {"type": "string"},
                            "description": "ì°¸ì„ì ì´ë©”ì¼ ëª©ë¡"
                        }
                    },
                    "required": ["summary", "start_datetime", "end_datetime"]
                }
            }
        },
        {
            "type": "function",
            "function": {
                "name": "find_free_time",
                "description": "ì§€ì •ëœ ê¸°ê°„ ë™ì•ˆ ë¹ˆ ì‹œê°„ì„ ì°¾ìŠµë‹ˆë‹¤.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "duration_minutes": {
                            "type": "integer",
                            "description": "í•„ìš”í•œ ì‹œê°„ (ë¶„ ë‹¨ìœ„)"
                        },
                        "date_range": {
                            "type": "string",
                            "enum": ["today", "tomorrow", "this_week", "next_week"],
                            "description": "ê²€ìƒ‰í•  ë‚ ì§œ ë²”ìœ„"
                        },
                        "working_hours_only": {
                            "type": "boolean",
                            "default": True,
                            "description": "ì—…ë¬´ ì‹œê°„(9-18ì‹œ)ë§Œ ê²€ìƒ‰í• ì§€ ì—¬ë¶€"
                        }
                    },
                    "required": ["duration_minutes", "date_range"]
                }
            }
        },
        {
            "type": "function",
            "function": {
                "name": "get_emails",
                "description": "Gmailì—ì„œ ì´ë©”ì¼ì„ ì¡°íšŒí•©ë‹ˆë‹¤.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "query": {
                            "type": "string",
                            "description": "ê²€ìƒ‰ ì¿¼ë¦¬ (ì˜ˆ: 'subject:íšŒì˜', 'from:manager@company.com')"
                        },
                        "max_results": {
                            "type": "integer",
                            "default": 10,
                            "description": "ìµœëŒ€ ì¡°íšŒí•  ì´ë©”ì¼ ìˆ˜"
                        },
                        "time_period": {
                            "type": "string",
                            "enum": ["today", "this_week", "this_month", "all"],
                            "default": "this_week",
                            "description": "ì¡°íšŒí•  ì‹œê°„ ë²”ìœ„"
                        }
                    }
                }
            }
        },
        {
            "type": "function",
            "function": {
                "name": "send_email",
                "description": "Gmailì„ í†µí•´ ì´ë©”ì¼ì„ ë°œì†¡í•©ë‹ˆë‹¤.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "to": {
                            "type": "array",
                            "items": {"type": "string"},
                            "description": "ìˆ˜ì‹ ì ì´ë©”ì¼ ì£¼ì†Œ ëª©ë¡"
                        },
                        "subject": {
                            "type": "string",
                            "description": "ì´ë©”ì¼ ì œëª©"
                        },
                        "body": {
                            "type": "string",
                            "description": "ì´ë©”ì¼ ë³¸ë¬¸"
                        },
                        "cc": {
                            "type": "array",
                            "items": {"type": "string"},
                            "description": "ì°¸ì¡° ì´ë©”ì¼ ì£¼ì†Œ ëª©ë¡"
                        }
                    },
                    "required": ["to", "subject", "body"]
                }
            }
        }
    ]

# ìº˜ë¦°ë” ì¼ì •ì„ í‘œ í˜•íƒœë¡œ í¬ë§·íŒ…í•˜ëŠ” í•¨ìˆ˜
def format_calendar_events_as_table(events: List[Dict]) -> str:
    """ìº˜ë¦°ë” ì¼ì •ì„ ë§ˆí¬ë‹¤ìš´ í‘œ í˜•íƒœë¡œ í¬ë§·íŒ…"""
    if not events:
        return "ì¡°íšŒëœ ì¼ì •ì´ ì—†ìŠµë‹ˆë‹¤."
    
    # í‘œ í—¤ë”
    table = "## ğŸ“… ì¼ì • ëª©ë¡\n\n"
    table += "| ë‚ ì§œ | ì‹œê°„ | ì œëª© | ì¥ì†Œ | ì„¤ëª… |\n"
    table += "|------|------|------|------|------|\n"
    
    for event in events:
        # ë‚ ì§œ/ì‹œê°„ íŒŒì‹±
        start_time = event.get('start', '')
        summary = event.get('summary', 'ì œëª© ì—†ìŒ')
        location = event.get('location', '-')
        description = event.get('description', '-')
        
        # ë‚ ì§œì™€ ì‹œê°„ ë¶„ë¦¬
        if 'T' in start_time:
            try:
                from datetime import datetime
                dt = datetime.fromisoformat(start_time.replace('Z', '+00:00'))
                date_str = dt.strftime('%m/%d')
                time_str = dt.strftime('%H:%M')
                
                # ì¢…ë£Œ ì‹œê°„ë„ íŒŒì‹±
                end_time = event.get('end', '')
                if 'T' in end_time:
                    end_dt = datetime.fromisoformat(end_time.replace('Z', '+00:00'))
                    time_str += f" - {end_dt.strftime('%H:%M')}"
            except:
                date_str = start_time[:10] if len(start_time) >= 10 else start_time
                time_str = start_time[11:16] if len(start_time) > 16 else "-"
        else:
            date_str = start_time
            time_str = "ì¢…ì¼"
        
        # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (í‘œê°€ ë„ˆë¬´ ê¸¸ì–´ì§€ì§€ ì•Šë„ë¡)
        summary = (summary[:20] + "...") if len(summary) > 20 else summary
        location = (location[:15] + "...") if len(location) > 15 else location
        description = (description[:25] + "...") if len(description) > 25 else description
        
        # ë§ˆí¬ë‹¤ìš´ íŠ¹ìˆ˜ë¬¸ì ì´ìŠ¤ì¼€ì´í”„
        summary = summary.replace('|', '\\|')
        location = location.replace('|', '\\|')
        description = description.replace('|', '\\|')
        
        table += f"| {date_str} | {time_str} | {summary} | {location} | {description} |\n"
    
    table += f"\nì´ **{len(events)}ê°œ**ì˜ ì¼ì •ì´ ìˆìŠµë‹ˆë‹¤."
    return table

# Google í•¨ìˆ˜ ì‹¤í–‰ í•¸ë“¤ëŸ¬
async def execute_google_function(function_name: str, arguments: dict):
    """Google í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜"""
    try:
        if not GOOGLE_SERVICES_AVAILABLE or not auth_service.is_authenticated():
            return {"error": "Google ì„œë¹„ìŠ¤ê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € Google ì¸ì¦ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”."}
        
        if function_name == "get_calendar_events":
            from datetime import datetime, timedelta
            
            # time_periodë¥¼ start_date, end_dateë¡œ ë³€í™˜
            time_period = arguments.get("time_period", "today")
            today = datetime.now().date()
            
            if time_period == "today":
                start_date = today.isoformat()
                end_date = today.isoformat()
            elif time_period == "tomorrow":
                tomorrow = today + timedelta(days=1)
                start_date = tomorrow.isoformat()
                end_date = tomorrow.isoformat()
            elif time_period == "this_week":
                # ì´ë²ˆ ì£¼ ì›”ìš”ì¼ë¶€í„° ì¼ìš”ì¼ê¹Œì§€
                days_since_monday = today.weekday()
                monday = today - timedelta(days=days_since_monday)
                sunday = monday + timedelta(days=6)
                start_date = monday.isoformat()
                end_date = sunday.isoformat()
            elif time_period == "next_week":
                # ë‹¤ìŒ ì£¼ ì›”ìš”ì¼ë¶€í„° ì¼ìš”ì¼ê¹Œì§€
                days_since_monday = today.weekday()
                next_monday = today - timedelta(days=days_since_monday) + timedelta(days=7)
                next_sunday = next_monday + timedelta(days=6)
                start_date = next_monday.isoformat()
                end_date = next_sunday.isoformat()
            elif time_period == "this_month":
                # ì´ë²ˆ ë‹¬ 1ì¼ë¶€í„° ë§ì¼ê¹Œì§€
                first_day = today.replace(day=1)
                if today.month == 12:
                    last_day = today.replace(year=today.year+1, month=1, day=1) - timedelta(days=1)
                else:
                    last_day = today.replace(month=today.month+1, day=1) - timedelta(days=1)
                start_date = first_day.isoformat()
                end_date = last_day.isoformat()
            elif time_period == "next_month":
                # ë‹¤ìŒ ë‹¬ 1ì¼ë¶€í„° ë§ì¼ê¹Œì§€
                if today.month == 12:
                    next_month_first = today.replace(year=today.year+1, month=1, day=1)
                    next_month_last = today.replace(year=today.year+1, month=2, day=1) - timedelta(days=1)
                else:
                    next_month_first = today.replace(month=today.month+1, day=1)
                    if today.month == 11:
                        next_month_last = today.replace(year=today.year+1, month=1, day=1) - timedelta(days=1)
                    else:
                        next_month_last = today.replace(month=today.month+2, day=1) - timedelta(days=1)
                start_date = next_month_first.isoformat()
                end_date = next_month_last.isoformat()
            else:
                # ê¸°ë³¸ê°’ì€ ì˜¤ëŠ˜
                start_date = today.isoformat()
                end_date = today.isoformat()
            
            result = await calendar_service.get_events(
                start_date=start_date,
                end_date=end_date,
                max_results=arguments.get("max_results", 10)
            )
            return result
            
        elif function_name == "create_calendar_event":
            from google_services import CalendarEvent
            event_data = CalendarEvent(
                summary=arguments["summary"],
                description=arguments.get("description", ""),
                start_datetime=arguments["start_datetime"],
                end_datetime=arguments["end_datetime"],
                attendees=arguments.get("attendees", [])
            )
            result = await calendar_service.create_event(event_data)
            return result
            
        elif function_name == "find_free_time":
            result = await calendar_service.find_free_time(
                duration_minutes=arguments["duration_minutes"],
                date_range=arguments["date_range"],
                working_hours_only=arguments.get("working_hours_only", True)
            )
            return result
            
        elif function_name == "get_emails":
            result = await gmail_service.get_emails(
                query=arguments.get("query", ""),
                max_results=arguments.get("max_results", 10),
                time_period=arguments.get("time_period", "this_week")
            )
            return result
            
        elif function_name == "send_email":
            from google_services import EmailMessage
            email_data = EmailMessage(
                to=arguments["to"],
                subject=arguments["subject"],
                body=arguments["body"],
                cc=arguments.get("cc", [])
            )
            result = await gmail_service.send_email(email_data)
            return result
            
        else:
            return {"error": f"ì•Œ ìˆ˜ ì—†ëŠ” í•¨ìˆ˜: {function_name}"}
            
    except Exception as e:
        print(f"Google function execution error: {e}")
        return {"error": f"í•¨ìˆ˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}

# Pydantic ëª¨ë¸ë“¤
class ChatMessage(BaseModel):
    id: str
    content: str
    role: str  # 'user' or 'assistant'
    timestamp: datetime
    sessionId: str

class ChatRequest(BaseModel):
    content: str
    sessionId: str
    model: Optional[str] = "gpt-4o"  # ê¸°ë³¸ê°’ì€ gpt-4o
    webSearch: Optional[bool] = False  # ì›¹ ê²€ìƒ‰ ì—¬ë¶€

class ChatResponse(BaseModel):
    id: str
    content: str
    role: str
    timestamp: datetime
    sessionId: str

class ChatSession(BaseModel):
    id: str
    title: str
    createdAt: datetime
    updatedAt: datetime
    messageCount: int

class SessionCreateRequest(BaseModel):
    title: Optional[str] = None

class SessionUpdateRequest(BaseModel):
    title: str

class ChatSearch(BaseModel):
    query: Optional[str] = None
    page: int = 0
    size: int = 50
    sort: Optional[str] = None

class ChatSessionList(BaseModel):
    sessions: List[ChatSession]
    totalElements: int
    totalPages: int
    currentPage: int
    size: int

class ChatHistory(BaseModel):
    messages: List[ChatMessage]
    sessionId: str
    totalCount: int

class ChatStreamChunk(BaseModel):
    id: str
    content: str
    role: str
    timestamp: datetime
    sessionId: str
    isComplete: bool = False

# íŒŒì¼ ì²˜ë¦¬ í•¨ìˆ˜ë“¤
async def extract_text_from_pdf(file_content: bytes) -> str:
    """PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        pdf_file = io.BytesIO(file_content)
        pdf_reader = PyPDF2.PdfReader(pdf_file)
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text() + "\n"
        return text.strip()
    except Exception as e:
        return f"PDF ì½ê¸° ì˜¤ë¥˜: {str(e)}"

async def extract_text_from_docx(file_content: bytes) -> str:
    """DOCX íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        doc_file = io.BytesIO(file_content)
        doc = docx.Document(doc_file)
        text = ""
        for paragraph in doc.paragraphs:
            text += paragraph.text + "\n"
        return text.strip()
    except Exception as e:
        return f"DOCX ì½ê¸° ì˜¤ë¥˜: {str(e)}"

async def extract_text_from_image(file_content: bytes) -> str:
    """ì´ë¯¸ì§€ì—ì„œ OCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        image = Image.open(io.BytesIO(file_content))
        text = pytesseract.image_to_string(image, lang='kor+eng')
        return text.strip() if text.strip() else "ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    except Exception as e:
        return f"ì´ë¯¸ì§€ OCR ì˜¤ë¥˜: {str(e)}"

async def process_uploaded_file(file: UploadFile) -> str:
    """ì—…ë¡œë“œëœ íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        file_content = await file.read()
        file_type = file.content_type.lower()
        filename = file.filename.lower()
        
        if file_type == "application/pdf" or filename.endswith('.pdf'):
            return await extract_text_from_pdf(file_content)
        elif file_type in ["application/vnd.openxmlformats-officedocument.wordprocessingml.document"] or filename.endswith('.docx'):
            return await extract_text_from_docx(file_content)
        elif file_type.startswith('image/'):
            return await extract_text_from_image(file_content)
        elif file_type == "text/plain" or filename.endswith('.txt'):
            return file_content.decode('utf-8', errors='ignore')
        else:
            return f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_type}"
    except Exception as e:
        return f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}"

# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
def generate_id() -> str:
    return str(uuid.uuid4())

def create_session(title: str = None) -> ChatSession:
    session_id = generate_id()
    session = ChatSession(
        id=session_id,
        title=title or f"ìƒˆ ì±„íŒ… {len(sessions_db) + 1}",
        createdAt=datetime.now(),
        updatedAt=datetime.now(),
        messageCount=0
    )
    
    sessions_db[session_id] = session.dict()
    messages_db[session_id] = []
    return session

def get_session(session_id: str) -> ChatSession:
    if session_id not in sessions_db:
        raise HTTPException(status_code=404, detail="Session not found")
    return ChatSession(**sessions_db[session_id])

def update_session_message_count(session_id: str):
    if session_id in sessions_db:
        sessions_db[session_id]["messageCount"] = len(messages_db.get(session_id, []))
        sessions_db[session_id]["updatedAt"] = datetime.now()

# ì´ˆê¸° ë°ëª¨ ë°ì´í„° ìƒì„±
def initialize_demo_data():
    if not sessions_db:
        # ë°ëª¨ ì„¸ì…˜ 1
        demo_session_1 = create_session("ì˜ì—… ë°ì´í„° ë¶„ì„")
        messages_db[demo_session_1.id] = [
            {
                "id": generate_id(),
                "content": "ì´ë²ˆ ë¶„ê¸° ì˜ì—… ì„±ê³¼ëŠ” ì–´ë–¤ê°€ìš”?",
                "role": "user",
                "timestamp": datetime.now(),
                "sessionId": demo_session_1.id
            },
            {
                "id": generate_id(),
                "content": "ì´ë²ˆ ë¶„ê¸° ì˜ì—… ì„±ê³¼ë¥¼ ë¶„ì„í•´ë³´ê² ìŠµë‹ˆë‹¤. ì „ì²´ì ìœ¼ë¡œ ëª©í‘œ ëŒ€ë¹„ 115% ë‹¬ì„±í–ˆìœ¼ë©°, íŠ¹íˆ ìƒˆë¡œìš´ ê³ ê° í™•ë³´ ë¶€ë¶„ì—ì„œ ì¢‹ì€ ì„±ê³¼ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.",
                "role": "assistant",
                "timestamp": datetime.now(),
                "sessionId": demo_session_1.id
            }
        ]
        
        # ë°ëª¨ ì„¸ì…˜ 2
        demo_session_2 = create_session("í”„ë¡œì íŠ¸ í˜„í™© ì¡°íšŒ")
        messages_db[demo_session_2.id] = [
            {
                "id": generate_id(),
                "content": "ì§„í–‰ ì¤‘ì¸ í”„ë¡œì íŠ¸ ëª©ë¡ì„ ë³´ì—¬ì£¼ì„¸ìš”",
                "role": "user",
                "timestamp": datetime.now(),
                "sessionId": demo_session_2.id
            },
            {
                "id": generate_id(),
                "content": "í˜„ì¬ ì§„í–‰ ì¤‘ì¸ í”„ë¡œì íŠ¸ëŠ” ì´ 12ê°œì…ë‹ˆë‹¤. ê·¸ ì¤‘ 5ê°œëŠ” ê°œë°œ ë‹¨ê³„, 4ê°œëŠ” í…ŒìŠ¤íŠ¸ ë‹¨ê³„, 3ê°œëŠ” ë°°í¬ ì¤€ë¹„ ë‹¨ê³„ì— ìˆìŠµë‹ˆë‹¤.",
                "role": "assistant",
                "timestamp": datetime.now(),
                "sessionId": demo_session_2.id
            }
        ]
        
        # ë°ëª¨ ì„¸ì…˜ 3
        demo_session_3 = create_session("ê³ ê°ì‚¬ ì •ë³´ ë¬¸ì˜")
        messages_db[demo_session_3.id] = []
        
        # ë©”ì‹œì§€ ì¹´ìš´íŠ¸ ì—…ë°ì´íŠ¸
        for session_id in sessions_db.keys():
            update_session_message_count(session_id)

# ì•± ì‹œì‘ ì‹œ ë°ëª¨ ë°ì´í„° ì´ˆê¸°í™” (ë¹„í™œì„±í™”)
@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    # initialize_demo_data()  # ë°ëª¨ ë°ì´í„° ìƒì„± ë¹„í™œì„±í™”
    yield
    # Shutdown
    pass

app = FastAPI(
    title="NSales Pro Chat API",
    description="AI ì±„íŒ… ì„œë¹„ìŠ¤ API",
    version="1.0.0",
    lifespan=lifespan
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173", "http://localhost:5174", "http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# API ì—”ë“œí¬ì¸íŠ¸ë“¤

@app.get("/")
async def root():
    return {"message": "NSales Pro Chat API", "version": "1.0.0"}

@app.get("/api/v1/health")
async def health_check():
    return {"status": "healthy", "timestamp": datetime.now()}

@app.get("/api/v1/models")
async def get_available_models():
    """ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ ëª©ë¡ ë°˜í™˜"""
    return {"models": AVAILABLE_MODELS}

# Google ì„œë¹„ìŠ¤ ê´€ë ¨ ì—”ë“œí¬ì¸íŠ¸
@app.get("/api/v1/google/auth")
async def google_auth():
    """Google OAuth2 ì¸ì¦ ì‹œì‘"""
    if not GOOGLE_SERVICES_AVAILABLE:
        raise HTTPException(status_code=503, detail="Google ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    auth_url = auth_service.get_authorization_url()
    if not auth_url:
        raise HTTPException(status_code=500, detail="ì¸ì¦ URL ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    return {"auth_url": auth_url}

@app.get("/api/v1/google/callback")
async def google_callback(code: str):
    """Google OAuth2 ì½œë°± ì²˜ë¦¬"""
    if not GOOGLE_SERVICES_AVAILABLE:
        raise HTTPException(status_code=503, detail="Google ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    success = auth_service.handle_callback(code)
    if success:
        return RedirectResponse(url="http://localhost:5174?google_auth=success")
    else:
        return RedirectResponse(url="http://localhost:5174?google_auth=error")

@app.get("/api/v1/google/status")
async def google_status():
    """Google ì¸ì¦ ìƒíƒœ í™•ì¸"""
    if not GOOGLE_SERVICES_AVAILABLE:
        return {"authenticated": False, "error": "Google ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
    
    return {
        "authenticated": auth_service.is_authenticated(),
        "services_available": True
    }

# ì±„íŒ… ì„¸ì…˜ ê´€ë¦¬
@app.post("/api/v1/chat/sessions", response_model=ChatSession)
async def create_chat_session(request: SessionCreateRequest):
    session = create_session(request.title)
    return session

@app.get("/api/v1/chat/sessions", response_model=ChatSessionList)
async def get_chat_sessions(search: ChatSearch = Depends()):
    sessions = list(sessions_db.values())
    
    # ê²€ìƒ‰ í•„í„° ì ìš©
    if search.query:
        sessions = [
            s for s in sessions 
            if search.query.lower() in s["title"].lower()
        ]
    
    # ì •ë ¬ (ìµœì‹ ìˆœ)
    sessions.sort(key=lambda x: x["updatedAt"], reverse=True)
    
    # í˜ì´ì§•
    total = len(sessions)
    start = search.page * search.size
    end = start + search.size
    paged_sessions = sessions[start:end]
    
    return ChatSessionList(
        sessions=[ChatSession(**s) for s in paged_sessions],
        totalElements=total,
        totalPages=(total + search.size - 1) // search.size,
        currentPage=search.page,
        size=search.size
    )

@app.get("/api/v1/chat/sessions/{session_id}", response_model=ChatSession)
async def get_chat_session(session_id: str):
    return get_session(session_id)

@app.patch("/api/v1/chat/sessions/{session_id}")
async def update_chat_session(session_id: str, request: SessionUpdateRequest):
    if session_id not in sessions_db:
        raise HTTPException(status_code=404, detail="Session not found")
    
    sessions_db[session_id]["title"] = request.title
    sessions_db[session_id]["updatedAt"] = datetime.now()
    return {"message": "Session updated successfully"}

@app.delete("/api/v1/chat/sessions/{session_id}")
async def delete_chat_session(session_id: str):
    if session_id not in sessions_db:
        raise HTTPException(status_code=404, detail="Session not found")
    
    del sessions_db[session_id]
    if session_id in messages_db:
        del messages_db[session_id]
    
    return {"message": "Session deleted successfully"}

# ë©”ì‹œì§€ ê´€ë¦¬
@app.get("/api/v1/chat/sessions/{session_id}/messages", response_model=ChatHistory)
async def get_message_history(session_id: str):
    if session_id not in sessions_db:
        raise HTTPException(status_code=404, detail="Session not found")
    
    messages = messages_db.get(session_id, [])
    return ChatHistory(
        messages=[ChatMessage(**msg) for msg in messages],
        sessionId=session_id,
        totalCount=len(messages)
    )

@app.post("/api/v1/chat/messages/with-files")
async def send_message_with_files(
    content: str = Form(...),
    sessionId: str = Form(...),
    files: List[UploadFile] = File(default=[]),
    model: str = Form(default="gpt-4o")
):
    """íŒŒì¼ ì²¨ë¶€ë¥¼ ì§€ì›í•˜ëŠ” ì±„íŒ… ë©”ì‹œì§€ ì „ì†¡"""
    try:
        # ì„¸ì…˜ ì¡´ì¬ í™•ì¸
        if sessionId not in sessions_db:
            raise HTTPException(status_code=404, detail="Session not found")
        
        session_messages = messages_db.get(sessionId, [])
        
        # íŒŒì¼ ì²˜ë¦¬
        file_contents = []
        if files:
            for file in files:
                if file.filename:  # íŒŒì¼ì´ ì‹¤ì œë¡œ ì—…ë¡œë“œëœ ê²½ìš°
                    print(f"Processing file: {file.filename}, type: {file.content_type}")
                    file_text = await process_uploaded_file(file)
                    file_contents.append(f"[íŒŒì¼: {file.filename}]\n{file_text}")
        
        # ë©”ì‹œì§€ ë‚´ìš© êµ¬ì„± (í…ìŠ¤íŠ¸ + íŒŒì¼ ë‚´ìš©)
        message_content = content
        if file_contents:
            message_content += "\n\n" + "\n\n".join(file_contents)
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
        user_message = ChatMessage(
            id=generate_id(),
            content=message_content,
            role="user",
            timestamp=datetime.now(),
            sessionId=sessionId
        )
        session_messages.append(user_message.model_dump())
        
        # OpenAI APIì— ì „ë‹¬í•  ë©”ì‹œì§€ êµ¬ì„±
        conversation_messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ NSales Proì˜ ì˜ì—… AI ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì˜ì—… ë°ì´í„° ë¶„ì„, í”„ë¡œì íŠ¸ ì •ë³´ ì¡°íšŒ, ì—…ë¬´ ê´€ë ¨ ì§ˆë¬¸ì— ë„ì›€ì„ ì£¼ì„¸ìš”. í•œêµ­ì–´ë¡œ ì¹œê·¼í•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”. ì²¨ë¶€ëœ íŒŒì¼ì˜ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ê´€ë ¨ëœ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”. ìµœì‹  ì •ë³´ê°€ í•„ìš”í•˜ê±°ë‚˜ ì‹¤ì‹œê°„ ë°ì´í„°, ë‰´ìŠ¤, ì‹œì¥ ë™í–¥ ë“±ì„ ì§ˆë¬¸ë°›ìœ¼ë©´ ì›¹ ê²€ìƒ‰ì„ ì ê·¹ í™œìš©í•˜ì—¬ ì •í™•í•˜ê³  ìµœì‹ ì˜ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”."}
        ]
        
        # ê¸°ì¡´ ëŒ€í™” ë‚´ìš© ì¶”ê°€ (ìµœê·¼ 20ê°œ ë©”ì‹œì§€ë§Œ ìœ ì§€)
        recent_messages = session_messages[-21:] if len(session_messages) > 21 else session_messages[:-1]  # í˜„ì¬ ë©”ì‹œì§€ ì œì™¸
        for msg in recent_messages:
            conversation_messages.append({
                "role": msg["role"],
                "content": msg["content"]
            })
        
        # í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        conversation_messages.append({"role": "user", "content": message_content})
        
        # ì„ íƒëœ ëª¨ë¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        selected_model = model if model in AVAILABLE_MODELS else "gpt-4o"
        model_config = AVAILABLE_MODELS[selected_model]

        # OpenAI API í˜¸ì¶œ
        try:
            print(f"Using model: {selected_model} ({model_config['name']})")
            print(f"Conversation length: {len(conversation_messages)} messages")
            print(f"Files processed: {len(file_contents)}")
            
            # ì›¹ ê²€ìƒ‰ ì—¬ë¶€ëŠ” form ë°ì´í„°ì—ì„œ í™•ì¸
            web_search = form.get('webSearch', 'false').lower() == 'true'
            needs_web_search = web_search
            
            if needs_web_search and model_config["supports_web_search"]:
                print("ğŸ” Web search detected - using Responses API with web search")
                try:
                    # OpenAI Responses APIë¥¼ ì‚¬ìš©í•œ ì›¹ ê²€ìƒ‰
                    response = await client.responses.create(
                        model=selected_model,
                        input=content,
                        tools=[
                            {
                                "type": "web_search"
                            }
                        ]
                    )
                    
                    # Extract message content from output
                    ai_content = ""
                    sources = []
                    
                    for output_item in response.output:
                        if output_item.type == 'message' and hasattr(output_item, 'content'):
                            for content_item in output_item.content:
                                if content_item.type == 'output_text':
                                    ai_content += content_item.text
                                    
                                    # Extract URL citations from annotations
                                    if hasattr(content_item, 'annotations'):
                                        for annotation in content_item.annotations:
                                            if annotation.type == 'url_citation':
                                                sources.append({
                                                    'title': getattr(annotation, 'title', ''),
                                                    'url': getattr(annotation, 'url', ''),
                                                    'snippet': ''
                                                })
                    
                    # Add sources to the content if found
                    if sources:
                        sources_text = "\n\n**ì°¸ê³  ì¶œì²˜:**\n"
                        for i, source in enumerate(sources, 1):
                            sources_text += f"{i}. [{source['title']}]({source['url']})\n"
                        ai_content += sources_text
                        print(f"ğŸ“š Found {len(sources)} web search sources")
                except Exception as e:
                    print(f"Responses API error, falling back to chat completions: {e}")
                    # Responses APIê°€ ì‘ë™í•˜ì§€ ì•Šìœ¼ë©´ ì¼ë°˜ ì±„íŒ…ìœ¼ë¡œ í´ë°±
                    response = await client.chat.completions.create(
                        model="gpt-4o",
                        messages=conversation_messages,
                        max_tokens=1500,
                        temperature=0.7
                    )
                    ai_content = response.choices[0].message.content
            else:
                # ê¸°ë³¸ ì±„íŒ… API í˜¸ì¶œ (Google ë„êµ¬ í¬í•¨)
                chat_params = {
                    "model": selected_model,
                    "messages": conversation_messages,
                    "max_tokens": model_config["max_tokens"],
                    "temperature": model_config["temperature"]
                }
                
                # Google ë„êµ¬ê°€ ìˆìœ¼ë©´ ì¶”ê°€
                if available_tools:
                    chat_params["tools"] = available_tools
                    chat_params["tool_choice"] = "auto"
                    print(f"ğŸ› ï¸ Function Calling í™œì„±í™”: {len(available_tools)}ê°œ ë„êµ¬")
                    print(f"ğŸ” ë„êµ¬ ëª©ë¡: {[tool['function']['name'] for tool in available_tools]}")
                    print(f"ğŸ” ìš”ì²­ ë‚´ìš©: {request.content}")
                
                response = await client.chat.completions.create(**chat_params)
                
                # Function callsê°€ ìˆëŠ”ì§€ í™•ì¸
                if response.choices[0].message.tool_calls:
                    print(f"ğŸ”§ Function í˜¸ì¶œ ê°ì§€: {len(response.choices[0].message.tool_calls)}ê°œ")
                    
                    function_results = []
                    for tool_call in response.choices[0].message.tool_calls:
                        function_name = tool_call.function.name
                        function_args = json.loads(tool_call.function.arguments)
                        
                        print(f"ğŸ”§ ì‹¤í–‰ ì¤‘: {function_name}({function_args})")
                        result = await execute_google_function(function_name, function_args)
                        function_results.append(f"[{function_name} ê²°ê³¼]\n{json.dumps(result, ensure_ascii=False, indent=2)}")
                    
                    # í•¨ìˆ˜ ê²°ê³¼ë¥¼ AI ì‘ë‹µì— í¬í•¨
                    ai_content = response.choices[0].message.content or ""
                    if function_results:
                        ai_content += "\n\n" + "\n\n".join(function_results)
                        print(f"ğŸ“‹ í•¨ìˆ˜ ì‹¤í–‰ ê²°ê³¼ê°€ ì‘ë‹µì— ì¶”ê°€ë¨")
                else:
                    ai_content = response.choices[0].message.content
            
            print(f"OpenAI Response: {ai_content}")
            
        except Exception as e:
            print(f"OpenAI API Error: {e}")
            ai_content = f"ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ AI ì„œë¹„ìŠ¤ì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì²¨ë¶€í•˜ì‹  íŒŒì¼ì„ í¬í•¨í•œ '{content}'ì— ëŒ€í•œ ë‹µë³€ì„ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        
        # AI ì‘ë‹µ ì €ì¥
        ai_message = ChatMessage(
            id=generate_id(),
            content=ai_content,
            role="assistant",
            timestamp=datetime.now(),
            sessionId=sessionId
        )
        session_messages.append(ai_message.model_dump())
        
        # ë©”ì‹œì§€ ì €ì¥
        messages_db[sessionId] = session_messages
        
        # ì„¸ì…˜ ì—…ë°ì´íŠ¸
        sessions_db[sessionId]["messageCount"] = len(session_messages)
        sessions_db[sessionId]["updatedAt"] = datetime.now()
        
        return {
            "userMessage": user_message,
            "aiMessage": ai_message,
            "success": True
        }
        
    except Exception as e:
        print(f"Error in send_message_with_files: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/v1/chat/messages", response_model=ChatResponse)
async def send_message(request: ChatRequest):
    if request.sessionId not in sessions_db:
        raise HTTPException(status_code=404, detail="Session not found")
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
    user_message = ChatMessage(
        id=generate_id(),
        content=request.content,
        role="user",
        timestamp=datetime.now(),
        sessionId=request.sessionId
    )
    
    if request.sessionId not in messages_db:
        messages_db[request.sessionId] = []
    
    messages_db[request.sessionId].append(user_message.dict())
    
    # ì„¸ì…˜ì˜ ê¸°ì¡´ ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸°
    session_messages = messages_db.get(request.sessionId, [])
    
    # Google ì„œë¹„ìŠ¤ ì‚¬ìš© ì•ˆë‚´ë¥¼ í¬í•¨í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    system_prompt = "ë‹¹ì‹ ì€ NSales Proì˜ ì˜ì—… AI ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì˜ì—… ë°ì´í„° ë¶„ì„, í”„ë¡œì íŠ¸ ì •ë³´ ì¡°íšŒ, ì—…ë¬´ ê´€ë ¨ ì§ˆë¬¸ì— ë„ì›€ì„ ì£¼ì„¸ìš”. í•œêµ­ì–´ë¡œ ì¹œê·¼í•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”. ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ê¸°ì–µí•˜ê³  ë¬¸ë§¥ì„ ìœ ì§€í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”. ìµœì‹  ì •ë³´ê°€ í•„ìš”í•˜ê±°ë‚˜ ì‹¤ì‹œê°„ ë°ì´í„°, ë‰´ìŠ¤, ì‹œì¥ ë™í–¥ ë“±ì„ ì§ˆë¬¸ë°›ìœ¼ë©´ ì›¹ ê²€ìƒ‰ì„ ì ê·¹ í™œìš©í•˜ì—¬ ì •í™•í•˜ê³  ìµœì‹ ì˜ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”."
    
    # ë©˜ì…˜ ê¸°ë°˜ ì„œë¹„ìŠ¤ í™œì„±í™” ë¡œì§
    mention_detected = False
    google_mention_keywords = ['@ìº˜ë¦°ë”', '@ë©”ì¼', '@ì¼ì •ìƒì„±', '@ë¹ˆì‹œê°„']
    
    for keyword in google_mention_keywords:
        if keyword in request.content:
            mention_detected = True
            break
    
    # Google ì„œë¹„ìŠ¤ê°€ ì‚¬ìš© ê°€ëŠ¥í•˜ê³  ë©˜ì…˜ì´ ê°ì§€ëœ ê²½ìš° ì•ˆë‚´ ì¶”ê°€
    if GOOGLE_SERVICES_AVAILABLE and auth_service.is_authenticated() and mention_detected:
        system_prompt += "\n\n**ğŸ¯ Google ì„œë¹„ìŠ¤ ë©˜ì…˜ ê°ì§€ë¨:**\nì‚¬ìš©ìê°€ @ë©˜ì…˜ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ í•¨ìˆ˜ë¥¼ ë°˜ë“œì‹œ í˜¸ì¶œí•˜ì—¬ ìš”ì²­ì„ ì²˜ë¦¬í•˜ì„¸ìš”:\n- @ìº˜ë¦°ë” â†’ get_calendar_events í•¨ìˆ˜ í˜¸ì¶œ\n- @ë©”ì¼ â†’ get_emails ë˜ëŠ” send_email í•¨ìˆ˜ í˜¸ì¶œ\n- @ì¼ì •ìƒì„± â†’ create_calendar_event í•¨ìˆ˜ í˜¸ì¶œ\n- @ë¹ˆì‹œê°„ â†’ find_free_time í•¨ìˆ˜ í˜¸ì¶œ\n\në©˜ì…˜ì´ í¬í•¨ëœ ìš”ì²­ì€ ë°˜ë“œì‹œ í•´ë‹¹ í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•˜ì—¬ ì‹¤ì œ ë°ì´í„°ë¥¼ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤."
    elif GOOGLE_SERVICES_AVAILABLE and auth_service.is_authenticated():
        system_prompt += "\n\n**Google ì„œë¹„ìŠ¤ ì—°ë™ ì•ˆë‚´:**\nì‚¬ìš©ìê°€ ìº˜ë¦°ë”, ì¼ì •, ìŠ¤ì¼€ì¤„, Gmail, ì´ë©”ì¼ ê´€ë ¨ ì§ˆë¬¸ì„ í•˜ë©´ ë‹¤ìŒ í•¨ìˆ˜ë“¤ì„ ì ê·¹ í™œìš©í•˜ì„¸ìš”:\n- get_calendar_events: ìº˜ë¦°ë” ì¼ì • ì¡°íšŒ (ì˜¤ëŠ˜, ì´ë²ˆì£¼, ì´ë²ˆë‹¬ ë“±)\n- create_calendar_event: ìƒˆ ì¼ì • ìƒì„±\n- send_email: ì´ë©”ì¼ ì „ì†¡\n- get_emails: ì´ë©”ì¼ ì¡°íšŒ\n- find_free_time: ë¹ˆ ì‹œê°„ ì°¾ê¸°\n\nì‚¬ìš©ìê°€ 'ìº˜ë¦°ë”', 'ì¼ì •', 'ìŠ¤ì¼€ì¤„' ë“±ì˜ í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•˜ë©´ ë°˜ë“œì‹œ í•´ë‹¹ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ì‹¤ì œ ë°ì´í„°ë¥¼ ì œê³µí•˜ì„¸ìš”."
    
    # OpenAI APIì— ì „ë‹¬í•  ë©”ì‹œì§€ êµ¬ì„±
    conversation_messages = [
        {"role": "system", "content": system_prompt}
    ]
    
    # ê¸°ì¡´ ëŒ€í™” ë‚´ìš© ì¶”ê°€ (ìµœê·¼ 10ê°œ ë©”ì‹œì§€ë§Œ ìœ ì§€í•˜ì—¬ í† í° ì ˆì•½)
    recent_messages = session_messages[-20:] if len(session_messages) > 20 else session_messages
    for msg in recent_messages:
        conversation_messages.append({
            "role": msg["role"],
            "content": msg["content"]
        })
    
    # í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    conversation_messages.append({"role": "user", "content": request.content})
    
    # ì„ íƒëœ ëª¨ë¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    selected_model = request.model if request.model in AVAILABLE_MODELS else "gpt-4o"
    model_config = AVAILABLE_MODELS[selected_model]
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ êµ¬ì„±
    available_tools = []
    if GOOGLE_SERVICES_AVAILABLE and auth_service.is_authenticated():
        available_tools.extend(get_google_tools())
        print(f"ğŸ› ï¸ Google ë„êµ¬ {len(get_google_tools())}ê°œ ì¶”ê°€ë¨")
    
    # OpenAI API í˜¸ì¶œ
    try:
        print(f"Using model: {selected_model} ({model_config['name']})")
        print(f"OpenAI API Key: {os.getenv('OPENAI_API_KEY')[:20]}...")  # ë””ë²„ê¹…ìš©
        print(f"Conversation length: {len(conversation_messages)} messages")  # ë””ë²„ê¹…ìš©
        
        # ì›¹ ê²€ìƒ‰ ì—¬ë¶€ëŠ” ìš”ì²­ì—ì„œ í™•ì¸
        needs_web_search = getattr(request, 'webSearch', False)
        search_content = request.content
        
        # ì›¹ ê²€ìƒ‰ì€ ì§€ì›í•˜ëŠ” ëª¨ë¸ì—ì„œë§Œ ê°€ëŠ¥
        if needs_web_search and model_config["supports_web_search"]:
            print("ğŸ” Web search detected - using Responses API with web search")
            try:
                # OpenAI Responses APIë¥¼ ì‚¬ìš©í•œ ì›¹ ê²€ìƒ‰
                response = await client.responses.create(
                    model=selected_model,
                    input=search_content,
                    tools=[
                        {
                            "type": "web_search"
                        }
                    ]
                )
                
                # Extract message content from output
                ai_content = ""
                sources = []
                
                for output_item in response.output:
                    if output_item.type == 'message' and hasattr(output_item, 'content'):
                        for content_item in output_item.content:
                            if content_item.type == 'output_text':
                                ai_content += content_item.text
                                
                                # Extract URL citations from annotations
                                if hasattr(content_item, 'annotations'):
                                    for annotation in content_item.annotations:
                                        if annotation.type == 'url_citation':
                                            sources.append({
                                                'title': getattr(annotation, 'title', ''),
                                                'url': getattr(annotation, 'url', ''),
                                                'snippet': ''
                                            })
                
                # Add sources to the content if found
                if sources:
                    sources_text = "\n\n**ì°¸ê³  ì¶œì²˜:**\n"
                    for i, source in enumerate(sources, 1):
                        sources_text += f"{i}. [{source['title']}]({source['url']})\n"
                    ai_content += sources_text
                    print(f"ğŸ“š Found {len(sources)} web search sources")
            except Exception as e:
                print(f"Responses API error, falling back to chat completions: {e}")
                # Responses APIê°€ ì‘ë™í•˜ì§€ ì•Šìœ¼ë©´ ì¼ë°˜ ì±„íŒ…ìœ¼ë¡œ í´ë°±
                response = await client.chat.completions.create(
                    model=selected_model,
                    messages=conversation_messages,
                    max_tokens=model_config["max_tokens"],
                    temperature=model_config["temperature"]
                )
                ai_content = response.choices[0].message.content
        else:
            # ê¸°ë³¸ ì±„íŒ… API í˜¸ì¶œ (Google ë„êµ¬ í¬í•¨)
            chat_params = {
                "model": selected_model,
                "messages": conversation_messages,
                "max_tokens": model_config["max_tokens"],
                "temperature": model_config["temperature"]
            }
            
            # Google ë„êµ¬ê°€ ìˆìœ¼ë©´ ì¶”ê°€
            if available_tools:
                chat_params["tools"] = available_tools
                chat_params["tool_choice"] = "auto"
                print(f"ğŸ› ï¸ Function Calling í™œì„±í™”: {len(available_tools)}ê°œ ë„êµ¬")
                print(f"ğŸ” ë„êµ¬ ëª©ë¡: {[tool['function']['name'] for tool in available_tools]}")
                print(f"ğŸ” ìš”ì²­ ë‚´ìš©: {request.content}")
            
            response = await client.chat.completions.create(**chat_params)
            
            # Function callsê°€ ìˆëŠ”ì§€ í™•ì¸
            if response.choices[0].message.tool_calls:
                print(f"ğŸ”§ Function í˜¸ì¶œ ê°ì§€: {len(response.choices[0].message.tool_calls)}ê°œ")
                
                function_results = []
                for tool_call in response.choices[0].message.tool_calls:
                    function_name = tool_call.function.name
                    function_args = json.loads(tool_call.function.arguments)
                    
                    print(f"ğŸ”§ ì‹¤í–‰ ì¤‘: {function_name}({function_args})")
                    result = await execute_google_function(function_name, function_args)
                    function_results.append(f"[{function_name} ê²°ê³¼]\n{json.dumps(result, ensure_ascii=False, indent=2)}")
                
                # í•¨ìˆ˜ ê²°ê³¼ê°€ ìˆìœ¼ë©´ AIê°€ í•´ì„í•˜ë„ë¡ ì²˜ë¦¬
                if function_results:
                    # ì²« ë²ˆì§¸ í•¨ìˆ˜ ê²°ê³¼ë§Œ ì‚¬ìš© (ì—¬ëŸ¬ í•¨ìˆ˜ í˜¸ì¶œì‹œ ê³ ë ¤ í•„ìš”)
                    first_tool_call = response.choices[0].message.tool_calls[0]
                    first_result = await execute_google_function(first_tool_call.function.name, json.loads(first_tool_call.function.arguments))
                    
                    # ê²°ê³¼ê°€ ë¹ˆ ë¦¬ìŠ¤íŠ¸ì´ë©´ ì ì ˆí•œ ë©”ì‹œì§€ë¡œ ë³€í™˜
                    if isinstance(first_result, list) and len(first_result) == 0:
                        if first_tool_call.function.name == "get_calendar_events":
                            ai_content = "í•´ë‹¹ ê¸°ê°„ì— ì˜ˆì •ëœ ì¼ì •ì´ ì—†ìŠµë‹ˆë‹¤. ììœ ë¡œìš´ ì‹œê°„ì„ ë³´ë‚´ì„¸ìš”! ğŸ˜Š"
                        else:
                            ai_content = "ì¡°íšŒëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
                    elif "error" in str(first_result):
                        ai_content = f"ì£„ì†¡í•©ë‹ˆë‹¤. {first_tool_call.function.name} ì‹¤í–‰ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {first_result.get('error', str(first_result))}"
                    else:
                        # ìº˜ë¦°ë” ì¼ì •ì€ í‘œ í˜•íƒœë¡œ í¬ë§·íŒ…
                        if first_tool_call.function.name == "get_calendar_events" and isinstance(first_result, list):
                            ai_content = format_calendar_events_as_table(first_result)
                        else:
                            # ë‹¤ë¥¸ í•¨ìˆ˜ëŠ” ê¸°ë³¸ JSON í˜•íƒœ
                            ai_content = f"{response.choices[0].message.content or ''}\n\nì¡°íšŒ ê²°ê³¼:\n{json.dumps(first_result, ensure_ascii=False, indent=2)}"
                    
                    print(f"ğŸ“‹ í•¨ìˆ˜ ê²°ê³¼ í•´ì„ ì™„ë£Œ: {first_tool_call.function.name}")
                else:
                    ai_content = response.choices[0].message.content or ""
            else:
                ai_content = response.choices[0].message.content
        
        print(f"OpenAI Response: {ai_content}")  # ë””ë²„ê¹…ìš©
        
    except Exception as e:
        # OpenAI API ì˜¤ë¥˜ ì‹œ í´ë°± ì‘ë‹µ
        print(f"OpenAI API Error: {e}")  # ë””ë²„ê¹…ìš©
        ai_content = f"ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ AI ì„œë¹„ìŠ¤ì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. '{request.content}'ì— ëŒ€í•œ ë‹µë³€ì„ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    
    # AI ì‘ë‹µ ì €ì¥
    ai_message = ChatMessage(
        id=generate_id(),
        content=ai_content,
        role="assistant",
        timestamp=datetime.now(),
        sessionId=request.sessionId
    )
    
    messages_db[request.sessionId].append(ai_message.dict())
    update_session_message_count(request.sessionId)
    
    return ChatResponse(**ai_message.dict())

# ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ… (ì„ì‹œë¡œ ì¼ë°˜ API ì‚¬ìš©)
@app.post("/api/v1/chat/stream")
async def stream_chat(request: ChatRequest):
    """ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ… API - ì„ì‹œë¡œ ì¼ë°˜ APIë¡œ í´ë°±"""
    try:
        # ì¼ë°˜ APIë¡œ ì²˜ë¦¬
        response = await send_message(request)
        
        # ì‘ë‹µì„ ìŠ¤íŠ¸ë¦¬ë° í˜•íƒœë¡œ ë³€í™˜
        content = response.content  # response.aiMessage.contentê°€ ì•„ë‹ˆë¼ response.content
        session_id = request.sessionId
        message_id = response.id  # response.aiMessage.idê°€ ì•„ë‹ˆë¼ response.id
        
        async def generate_stream():
            # ë¬¸ìë³„ë¡œ ìŠ¤íŠ¸ë¦¬ë°
            for i, char in enumerate(content):
                chunk = ChatStreamChunk(
                    id=message_id,
                    content=char,
                    role="assistant",
                    timestamp=datetime.now(),
                    sessionId=session_id,
                    isComplete=i == len(content) - 1
                )
                yield f"data: {chunk.json()}\n\n"
                await asyncio.sleep(0.01)
        
        return StreamingResponse(
            generate_stream(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "Access-Control-Allow-Origin": "*",
                "Access-Control-Allow-Headers": "Cache-Control"
            }
        )
    except Exception as e:
        print(f"Streaming error: {e}")
        # ì—ëŸ¬ ë°œìƒì‹œ í´ë°± ì‘ë‹µ
        error_chunk = ChatStreamChunk(
            id="error",
            content="ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ AI ì„œë¹„ìŠ¤ì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
            role="assistant",
            timestamp=datetime.now(),
            sessionId=request.sessionId,
            isComplete=True
        )
        
        async def error_stream():
            yield f"data: {error_chunk.json()}\n\n"
        
        return StreamingResponse(
            error_stream(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "Access-Control-Allow-Origin": "*",
                "Access-Control-Allow-Headers": "Cache-Control"
            }
        )

# ì›ë˜ ìŠ¤íŠ¸ë¦¬ë° í•¨ìˆ˜ (ì„ì‹œ ë¹„í™œì„±í™”)
@app.post("/api/v1/chat/stream_disabled")
async def stream_chat_original(request: ChatRequest):
    if request.sessionId not in sessions_db:
        raise HTTPException(status_code=404, detail="Session not found")
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
    user_message = ChatMessage(
        id=generate_id(),
        content=request.content,
        role="user",
        timestamp=datetime.now(),
        sessionId=request.sessionId
    )
    
    if request.sessionId not in messages_db:
        messages_db[request.sessionId] = []
    
    messages_db[request.sessionId].append(user_message.dict())
    
    async def generate_stream():
        ai_message_id = generate_id()
        full_content = ""
        
        # ì„¸ì…˜ì˜ ê¸°ì¡´ ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸°
        session_messages = messages_db.get(request.sessionId, [])
        
        # Google ì„œë¹„ìŠ¤ ì‚¬ìš© ì•ˆë‚´ë¥¼ í¬í•¨í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt = "ë‹¹ì‹ ì€ NSales Proì˜ ì˜ì—… AI ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì˜ì—… ë°ì´í„° ë¶„ì„, í”„ë¡œì íŠ¸ ì •ë³´ ì¡°íšŒ, ì—…ë¬´ ê´€ë ¨ ì§ˆë¬¸ì— ë„ì›€ì„ ì£¼ì„¸ìš”. í•œêµ­ì–´ë¡œ ì¹œê·¼í•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”. ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ê¸°ì–µí•˜ê³  ë¬¸ë§¥ì„ ìœ ì§€í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”. ìµœì‹  ì •ë³´ê°€ í•„ìš”í•˜ê±°ë‚˜ ì‹¤ì‹œê°„ ë°ì´í„°, ë‰´ìŠ¤, ì‹œì¥ ë™í–¥ ë“±ì„ ì§ˆë¬¸ë°›ìœ¼ë©´ ì›¹ ê²€ìƒ‰ì„ ì ê·¹ í™œìš©í•˜ì—¬ ì •í™•í•˜ê³  ìµœì‹ ì˜ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”."
        
        # ë©˜ì…˜ ê¸°ë°˜ ì„œë¹„ìŠ¤ í™œì„±í™” ë¡œì§
        mention_detected = False
        google_mention_keywords = ['@ìº˜ë¦°ë”', '@ë©”ì¼', '@ì¼ì •ìƒì„±', '@ë¹ˆì‹œê°„']
        
        for keyword in google_mention_keywords:
            if keyword in request.content:
                mention_detected = True
                break
        
        # Google ì„œë¹„ìŠ¤ê°€ ì‚¬ìš© ê°€ëŠ¥í•˜ê³  ë©˜ì…˜ì´ ê°ì§€ëœ ê²½ìš° ì•ˆë‚´ ì¶”ê°€
        if GOOGLE_SERVICES_AVAILABLE and auth_service.is_authenticated() and mention_detected:
            system_prompt += "\n\n**ğŸ¯ Google ì„œë¹„ìŠ¤ ë©˜ì…˜ ê°ì§€ë¨:**\nì‚¬ìš©ìê°€ @ë©˜ì…˜ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ í•¨ìˆ˜ë¥¼ ë°˜ë“œì‹œ í˜¸ì¶œí•˜ì—¬ ìš”ì²­ì„ ì²˜ë¦¬í•˜ì„¸ìš”:\n- @ìº˜ë¦°ë” â†’ get_calendar_events í•¨ìˆ˜ í˜¸ì¶œ\n- @ë©”ì¼ â†’ get_emails ë˜ëŠ” send_email í•¨ìˆ˜ í˜¸ì¶œ\n- @ì¼ì •ìƒì„± â†’ create_calendar_event í•¨ìˆ˜ í˜¸ì¶œ\n- @ë¹ˆì‹œê°„ â†’ find_free_time í•¨ìˆ˜ í˜¸ì¶œ\n\në©˜ì…˜ì´ í¬í•¨ëœ ìš”ì²­ì€ ë°˜ë“œì‹œ í•´ë‹¹ í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•˜ì—¬ ì‹¤ì œ ë°ì´í„°ë¥¼ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤."
        elif GOOGLE_SERVICES_AVAILABLE and auth_service.is_authenticated():
            system_prompt += "\n\n**Google ì„œë¹„ìŠ¤ ì—°ë™ ì•ˆë‚´:**\nì‚¬ìš©ìê°€ ìº˜ë¦°ë”, ì¼ì •, ìŠ¤ì¼€ì¤„, Gmail, ì´ë©”ì¼ ê´€ë ¨ ì§ˆë¬¸ì„ í•˜ë©´ ë‹¤ìŒ í•¨ìˆ˜ë“¤ì„ ì ê·¹ í™œìš©í•˜ì„¸ìš”:\n- get_calendar_events: ìº˜ë¦°ë” ì¼ì • ì¡°íšŒ (ì˜¤ëŠ˜, ì´ë²ˆì£¼, ì´ë²ˆë‹¬ ë“±)\n- create_calendar_event: ìƒˆ ì¼ì • ìƒì„±\n- send_email: ì´ë©”ì¼ ì „ì†¡\n- get_emails: ì´ë©”ì¼ ì¡°íšŒ\n- find_free_time: ë¹ˆ ì‹œê°„ ì°¾ê¸°\n\nì‚¬ìš©ìê°€ 'ìº˜ë¦°ë”', 'ì¼ì •', 'ìŠ¤ì¼€ì¤„' ë“±ì˜ í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•˜ë©´ ë°˜ë“œì‹œ í•´ë‹¹ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ì‹¤ì œ ë°ì´í„°ë¥¼ ì œê³µí•˜ì„¸ìš”."
        
        # OpenAI APIì— ì „ë‹¬í•  ë©”ì‹œì§€ êµ¬ì„±
        conversation_messages = [
            {"role": "system", "content": system_prompt}
        ]
        
        # ê¸°ì¡´ ëŒ€í™” ë‚´ìš© ì¶”ê°€ (ìµœê·¼ 20ê°œ ë©”ì‹œì§€ë§Œ ìœ ì§€í•˜ì—¬ í† í° ì ˆì•½)
        recent_messages = session_messages[-20:] if len(session_messages) > 20 else session_messages
        for msg in recent_messages:
            conversation_messages.append({
                "role": msg["role"],
                "content": msg["content"]
            })
        
        # í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        conversation_messages.append({"role": "user", "content": request.content})
        
        try:
            # ì„ íƒëœ ëª¨ë¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            selected_model = request.model if request.model in AVAILABLE_MODELS else "gpt-4o"
            model_config = AVAILABLE_MODELS[selected_model]
            
            print(f"Stream using model: {selected_model} ({model_config['name']})")
            print(f"Stream conversation length: {len(conversation_messages)} messages")  # ë””ë²„ê¹…ìš©
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ êµ¬ì„±
            available_tools = []
            
            # ì›¹ ê²€ìƒ‰ ë„êµ¬ ì¶”ê°€
            if needs_web_search and model_config["supports_web_search"]:
                available_tools.append({"type": "web_search"})
            
            # Google ì„œë¹„ìŠ¤ ë„êµ¬ ì¶”ê°€ (ì¸ì¦ëœ ê²½ìš°ë§Œ)
            if GOOGLE_SERVICES_AVAILABLE and auth_service.is_authenticated():
                available_tools.extend(GOOGLE_TOOLS)
                print(f"ğŸ”— Google ì„œë¹„ìŠ¤ ë„êµ¬ {len(GOOGLE_TOOLS)}ê°œ ì¶”ê°€ë¨")
            
            # ì›¹ ê²€ìƒ‰ ì—¬ë¶€ëŠ” í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ê²°ì • (webSearch íŒŒë¼ë¯¸í„°ë¡œ ì „ë‹¬)
            needs_web_search = getattr(request, 'webSearch', False)
            search_content = request.content
            
            if needs_web_search and model_config["supports_web_search"]:
                print("ğŸ” Web search detected in stream - using Responses API")
                try:
                    # ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•œ ê²½ìš° ìŠ¤íŠ¸ë¦¬ë° ëŒ€ì‹  ì¼ë°˜ ì‘ë‹µ ì‚¬ìš©
                    response = await client.responses.create(
                        model=selected_model,
                        input=search_content,
                        tools=[
                            {
                                "type": "web_search"
                            }
                        ]
                    )
                    
                    # Extract message content from output
                    ai_content = ""
                    sources = []
                    
                    for output_item in response.output:
                        if output_item.type == 'message' and hasattr(output_item, 'content'):
                            for content_item in output_item.content:
                                if content_item.type == 'output_text':
                                    ai_content += content_item.text
                                    
                                    # Extract URL citations from annotations
                                    if hasattr(content_item, 'annotations'):
                                        for annotation in content_item.annotations:
                                            if annotation.type == 'url_citation':
                                                sources.append({
                                                    'title': getattr(annotation, 'title', ''),
                                                    'url': getattr(annotation, 'url', ''),
                                                    'snippet': ''
                                                })
                    
                    # Add sources to the content if found
                    if sources:
                        sources_text = "\n\n**ì°¸ê³  ì¶œì²˜:**\n"
                        for i, source in enumerate(sources, 1):
                            sources_text += f"{i}. [{source['title']}]({source['url']})\n"
                        ai_content += sources_text
                        print(f"ğŸ“š Found {len(sources)} web search sources in stream")
                    
                    full_content = ai_content
                    
                    # ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ìŠ¤íŠ¸ë¦¬ë°
                    import re
                    
                    # ë¬¸ìë³„ë¡œ ìŠ¤íŠ¸ë¦¬ë° (ë” ìì—°ìŠ¤ëŸ½ê²Œ)
                    for i, char in enumerate(ai_content):
                        stream_chunk = ChatStreamChunk(
                            id=ai_message_id,
                            content=char,
                            role="assistant",
                            timestamp=datetime.now(),
                            sessionId=request.sessionId,
                            isComplete=False
                        )
                        yield f"data: {stream_chunk.json()}\n\n"
                        
                        # ë¬¸ì ìœ í˜•ì— ë”°ë¥¸ ì ì‘ì  ì§€ì—°
                        if char in ".!?":
                            await asyncio.sleep(0.15)  # ë¬¸ì¥ ë
                        elif char in ",;:":
                            await asyncio.sleep(0.08)  # ë¬¸ì¥ ì¤‘ê°„
                        elif char == '\n':
                            await asyncio.sleep(0.12)  # ì¤„ë°”ê¿ˆ
                        elif char == ' ':
                            await asyncio.sleep(0.03)  # ê³µë°±
                        elif char in "()[]{}":
                            await asyncio.sleep(0.05)  # ê´„í˜¸
                        else:
                            await asyncio.sleep(0.02)  # ì¼ë°˜ ë¬¸ì
                    
                    # ì›¹ ê²€ìƒ‰ ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ ì‹ í˜¸
                    final_chunk = ChatStreamChunk(
                        id=ai_message_id,
                        content="",
                        role="assistant",
                        timestamp=datetime.now(),
                        sessionId=request.sessionId,
                        isComplete=True
                    )
                    yield f"data: {final_chunk.json()}\\n\\n"
                    
                    # ì›¹ ê²€ìƒ‰ ì„±ê³µ ì‹œ ì—¬ê¸°ì„œ return
                    # AI ì‘ë‹µ ì €ì¥
                    ai_message = ChatMessage(
                        id=ai_message_id,
                        content=full_content,
                        role="assistant",
                        timestamp=datetime.now(),
                        sessionId=request.sessionId
                    )
                    
                    messages_db[request.sessionId].append(ai_message.dict())
                    update_session_message_count(request.sessionId)
                    return
                        
                except Exception as web_error:
                    print(f"Responses API error in stream, falling back to chat completions: {web_error}")
                    # ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ì¼ë°˜ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ í´ë°±
                    stream = await client.chat.completions.create(
                        model=selected_model,
                        messages=conversation_messages,
                        max_tokens=model_config["max_tokens"],
                        temperature=model_config["temperature"],
                        stream=True
                    )
            else:
                # ì„ì‹œë¡œ ìŠ¤íŠ¸ë¦¬ë° ëŒ€ì‹  ì¼ë°˜ API ì‚¬ìš©
                chat_params = {
                    "model": selected_model,
                    "messages": conversation_messages,
                    "max_tokens": model_config["max_tokens"],
                    "temperature": model_config["temperature"]
                }
                
                # Google ë„êµ¬ê°€ ìˆìœ¼ë©´ ì¶”ê°€
                if available_tools and not needs_web_search:
                    chat_params["tools"] = available_tools
                    chat_params["tool_choice"] = "auto"
                    print(f"ğŸ› ï¸ Function Calling í™œì„±í™”: {len(available_tools)}ê°œ ë„êµ¬")
                
                print(f"ğŸ” ë¹„ìŠ¤íŠ¸ë¦¬ë° íŒŒë¼ë¯¸í„°: {chat_params}")
                response = await client.chat.completions.create(**chat_params)
                
                # ì‘ë‹µì„ ìŠ¤íŠ¸ë¦¬ë° í˜•íƒœë¡œ ë³€í™˜
                ai_content = response.choices[0].message.content
                
                # Function callsê°€ ìˆëŠ”ì§€ í™•ì¸
                if response.choices[0].message.tool_calls:
                    print(f"ğŸ”§ Function í˜¸ì¶œ ê°ì§€: {len(response.choices[0].message.tool_calls)}ê°œ")
                    
                    for tool_call in response.choices[0].message.tool_calls:
                        function_name = tool_call.function.name
                        function_args = json.loads(tool_call.function.arguments)
                        
                        if function_name in FUNCTION_MAP:
                            try:
                                # í•¨ìˆ˜ ì‹¤í–‰ ìƒíƒœ í‘œì‹œ
                                status_content = f"\n\nğŸ”„ {function_name} ì‹¤í–‰ ì¤‘...\n"
                                for char in status_content:
                                    status_chunk = ChatStreamChunk(
                                        id=ai_message_id,
                                        content=char,
                                        role="assistant",
                                        timestamp=datetime.now(),
                                        sessionId=request.sessionId,
                                        isComplete=False
                                    )
                                    yield f"data: {status_chunk.json()}\n\n"
                                    await asyncio.sleep(0.02)
                                
                                # í•¨ìˆ˜ ì‹¤í–‰
                                function_result = await FUNCTION_MAP[function_name](**function_args)
                                
                                # ê²°ê³¼ë¥¼ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì¶œë ¥
                                result_content = f"âœ… ê²°ê³¼:\n{function_result}\n\n"
                                ai_content += result_content
                                
                                for char in result_content:
                                    result_chunk = ChatStreamChunk(
                                        id=ai_message_id,
                                        content=char,
                                        role="assistant",
                                        timestamp=datetime.now(),
                                        sessionId=request.sessionId,
                                        isComplete=False
                                    )
                                    yield f"data: {result_chunk.json()}\n\n"
                                    await asyncio.sleep(0.02)
                                    
                            except Exception as e:
                                error_content = f"âŒ {function_name} ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}\n\n"
                                ai_content += error_content
                                
                                for char in error_content:
                                    error_chunk = ChatStreamChunk(
                                        id=ai_message_id,
                                        content=char,
                                        role="assistant",
                                        timestamp=datetime.now(),
                                        sessionId=request.sessionId,
                                        isComplete=False
                                    )
                                    yield f"data: {error_chunk.json()}\n\n"
                                    await asyncio.sleep(0.02)
                else:
                    # ì¼ë°˜ ì‘ë‹µì„ ë¬¸ìë³„ë¡œ ìŠ¤íŠ¸ë¦¬ë°
                    for char in ai_content:
                        stream_chunk = ChatStreamChunk(
                            id=ai_message_id,
                            content=char,
                            role="assistant",
                            timestamp=datetime.now(),
                            sessionId=request.sessionId,
                            isComplete=False
                        )
                        yield f"data: {stream_chunk.json()}\n\n"
                        await asyncio.sleep(0.02)
                
                full_content = ai_content
                
                # ì™„ë£Œ ì‹ í˜¸
                final_chunk = ChatStreamChunk(
                    id=ai_message_id,
                    content="",
                    role="assistant",
                    timestamp=datetime.now(),
                    sessionId=request.sessionId,
                    isComplete=True
                )
                yield f"data: {final_chunk.json()}\n\n"
                
                # AI ì‘ë‹µ ì €ì¥
                ai_message = ChatMessage(
                    id=ai_message_id,
                    content=full_content,
                    role="assistant",
                    timestamp=datetime.now(),
                    sessionId=request.sessionId
                )
                
                messages_db[request.sessionId].append(ai_message.dict())
                update_session_message_count(request.sessionId)
                return
            
            # ì¼ë°˜ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ (ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨í•˜ê±°ë‚˜ ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•˜ì§€ ì•Šì€ ê²½ìš°)
            tool_calls = []
            current_tool_call = None
            
            async for chunk in stream:
                delta = chunk.choices[0].delta
                
                # Function calling ì²˜ë¦¬
                if delta.tool_calls:
                    for tool_call_delta in delta.tool_calls:
                        if tool_call_delta.index == 0:
                            if current_tool_call is None:
                                current_tool_call = {
                                    "id": tool_call_delta.id or "",
                                    "function": {
                                        "name": tool_call_delta.function.name or "",
                                        "arguments": tool_call_delta.function.arguments or ""
                                    }
                                }
                            else:
                                if tool_call_delta.function.arguments:
                                    current_tool_call["function"]["arguments"] += tool_call_delta.function.arguments
                
                # ì¼ë°˜ í…ìŠ¤íŠ¸ ì‘ë‹µ ì²˜ë¦¬
                elif delta.content:
                    content = delta.content
                    full_content += content
                
                    stream_chunk = ChatStreamChunk(
                        id=ai_message_id,
                        content=content,
                        role="assistant",
                        timestamp=datetime.now(),
                        sessionId=request.sessionId,
                        isComplete=False
                    )
                    
                    yield f"data: {stream_chunk.json()}\n\n"
                    await asyncio.sleep(0.01)
                
                # ìŠ¤íŠ¸ë¦¼ ì™„ë£Œ ì²´í¬
                if chunk.choices[0].finish_reason == "tool_calls" and current_tool_call:
                    tool_calls.append(current_tool_call)
            
            # Function í˜¸ì¶œ ì‹¤í–‰
            if tool_calls:
                print(f"ğŸ”§ Function í˜¸ì¶œ ì‹¤í–‰: {len(tool_calls)}ê°œ")
                
                for tool_call in tool_calls:
                    function_name = tool_call["function"]["name"]
                    function_args = json.loads(tool_call["function"]["arguments"])
                    
                    if function_name in FUNCTION_MAP:
                        try:
                            # í•¨ìˆ˜ ì‹¤í–‰ ìƒíƒœ í‘œì‹œ
                            status_chunk = ChatStreamChunk(
                                id=ai_message_id,
                                content=f"\n\nğŸ”„ {function_name} ì‹¤í–‰ ì¤‘...\n",
                                role="assistant",
                                timestamp=datetime.now(),
                                sessionId=request.sessionId,
                                isComplete=False
                            )
                            yield f"data: {status_chunk.json()}\n\n"
                            
                            # í•¨ìˆ˜ ì‹¤í–‰
                            function_result = await FUNCTION_MAP[function_name](**function_args)
                            
                            # ê²°ê³¼ë¥¼ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì¶œë ¥
                            result_content = f"âœ… ê²°ê³¼:\n{function_result}\n\n"
                            full_content += result_content
                            
                            for char in result_content:
                                result_chunk = ChatStreamChunk(
                                    id=ai_message_id,
                                    content=char,
                                    role="assistant",
                                    timestamp=datetime.now(),
                                    sessionId=request.sessionId,
                                    isComplete=False
                                )
                                yield f"data: {result_chunk.json()}\n\n"
                                await asyncio.sleep(0.02)
                                
                        except Exception as e:
                            error_content = f"âŒ {function_name} ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}\n\n"
                            full_content += error_content
                            
                            for char in error_content:
                                error_chunk = ChatStreamChunk(
                                    id=ai_message_id,
                                    content=char,
                                    role="assistant",
                                    timestamp=datetime.now(),
                                    sessionId=request.sessionId,
                                    isComplete=False
                                )
                                yield f"data: {error_chunk.json()}\n\n"
                                await asyncio.sleep(0.02)
            
            # ì™„ë£Œ ì‹ í˜¸
            final_chunk = ChatStreamChunk(
                id=ai_message_id,
                content="",
                role="assistant",
                timestamp=datetime.now(),
                sessionId=request.sessionId,
                isComplete=True
            )
            yield f"data: {final_chunk.json()}\n\n"
            
        except Exception as e:
            # OpenAI API ì˜¤ë¥˜ ì‹œ í´ë°± ì‘ë‹µ
            print(f"ğŸš¨ ìŠ¤íŠ¸ë¦¬ë° API ì˜ˆì™¸ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            fallback_content = f"ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ AI ì„œë¹„ìŠ¤ì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. '{request.content}'ì— ëŒ€í•œ ë‹µë³€ì„ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            full_content = fallback_content
            
            # í´ë°± ì‘ë‹µì„ ë‹¨ì–´ ë‹¨ìœ„ë¡œ ìŠ¤íŠ¸ë¦¬ë°
            words = fallback_content.split()
            for i, word in enumerate(words):
                stream_chunk = ChatStreamChunk(
                    id=ai_message_id,
                    content=word + " ",
                    role="assistant",
                    timestamp=datetime.now(),
                    sessionId=request.sessionId,
                    isComplete=i == len(words) - 1
                )
                yield f"data: {stream_chunk.json()}\n\n"
                await asyncio.sleep(0.1)
        
        # AI ì‘ë‹µ ì €ì¥
        ai_message = ChatMessage(
            id=ai_message_id,
            content=full_content,
            role="assistant",
            timestamp=datetime.now(),
            sessionId=request.sessionId
        )
        
        messages_db[request.sessionId].append(ai_message.dict())
        update_session_message_count(request.sessionId)
    
    return StreamingResponse(
        generate_stream(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"  # Nginx ë²„í¼ë§ ë¹„í™œì„±í™”
        }
    )

@app.delete("/api/v1/chat/messages/{message_id}")
async def delete_message(message_id: str):
    for session_id, messages in messages_db.items():
        for i, msg in enumerate(messages):
            if msg["id"] == message_id:
                del messages[i]
                update_session_message_count(session_id)
                return {"message": "Message deleted successfully"}
    
    raise HTTPException(status_code=404, detail="Message not found")

@app.post("/api/v1/chat/messages/{message_id}/regenerate", response_model=ChatResponse)
async def regenerate_message(message_id: str):
    for session_id, messages in messages_db.items():
        for i, msg in enumerate(messages):
            if msg["id"] == message_id and msg["role"] == "assistant":
                # ì´ì „ ì‚¬ìš©ì ë©”ì‹œì§€ ì°¾ê¸°
                user_message = None
                if i > 0:
                    user_message = messages[i-1]
                
                if not user_message:
                    raise HTTPException(status_code=400, detail="Cannot regenerate: no previous user message found")
                
                try:
                    # ì„¸ì…˜ì˜ ê¸°ì¡´ ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸° (ì¬ìƒì„±í•  ë©”ì‹œì§€ ì œì™¸)
                    session_messages = messages_db.get(session_id, [])
                    
                    # OpenAI APIì— ì „ë‹¬í•  ë©”ì‹œì§€ êµ¬ì„±
                    conversation_messages = [
                        {"role": "system", "content": "ë‹¹ì‹ ì€ NSales Proì˜ ì˜ì—… AI ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì˜ì—… ë°ì´í„° ë¶„ì„, í”„ë¡œì íŠ¸ ì •ë³´ ì¡°íšŒ, ì—…ë¬´ ê´€ë ¨ ì§ˆë¬¸ì— ë„ì›€ì„ ì£¼ì„¸ìš”. í•œêµ­ì–´ë¡œ ì¹œê·¼í•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”. ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ê¸°ì–µí•˜ê³  ë¬¸ë§¥ì„ ìœ ì§€í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”."}
                    ]
                    
                    # ì¬ìƒì„±í•  ë©”ì‹œì§€ ì´ì „ê¹Œì§€ì˜ ëŒ€í™” ë‚´ìš© ì¶”ê°€
                    for j, msg in enumerate(session_messages):
                        if j >= i:  # ì¬ìƒì„±í•  ë©”ì‹œì§€ë¶€í„°ëŠ” ì œì™¸
                            break
                        conversation_messages.append({
                            "role": msg["role"],
                            "content": msg["content"]
                        })
                    
                    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
                    conversation_messages.append({"role": "user", "content": user_message["content"]})
                    
                    # OpenAI API í˜¸ì¶œ
                    response = await client.chat.completions.create(
                        model="gpt-4o",
                        messages=conversation_messages,
                        max_tokens=1000,
                        temperature=0.8  # ë” ë‹¤ì–‘í•œ ì‘ë‹µì„ ìœ„í•´ temperature ì¦ê°€
                    )
                    
                    new_content = response.choices[0].message.content
                    
                except Exception as e:
                    # OpenAI API ì˜¤ë¥˜ ì‹œ í´ë°± ì‘ë‹µ
                    new_content = f"ì£„ì†¡í•©ë‹ˆë‹¤. ë‹¤ì‹œ ìƒì„±í•˜ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. '{user_message['content']}'ì— ëŒ€í•œ ìƒˆë¡œìš´ ë‹µë³€ì„ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤."
                
                # ìƒˆë¡œìš´ ì‘ë‹µìœ¼ë¡œ êµì²´
                new_message = ChatMessage(
                    id=generate_id(),
                    content=new_content,
                    role="assistant",
                    timestamp=datetime.now(),
                    sessionId=session_id
                )
                
                messages[i] = new_message.dict()
                update_session_message_count(session_id)
                
                return ChatResponse(**new_message.dict())
    
    raise HTTPException(status_code=404, detail="Message not found")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)